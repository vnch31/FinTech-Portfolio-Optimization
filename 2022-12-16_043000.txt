2022-12-16 04:21:53,144 [DEBUG] use config:config.json
2022-12-16 04:21:53,145 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-16 04:21:53,145 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 1 year with 30 days

2022-12-16 04:21:53,145 [DEBUG] Getting data
2022-12-16 04:21:53,145 [DEBUG] Fetch data using the following parameters:
2022-12-16 04:21:53,145 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-16 04:21:53,145 [DEBUG] Start date: 2006-01-01
2022-12-16 04:21:53,145 [DEBUG] End date: 2022-10-01
2022-12-16 04:21:53,145 [DEBUG] Interval: 1d
2022-12-16 04:21:53,145 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-16 04:21:53,166 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-16 04:21:53,198 [DEBUG] Training and testing with the device: cuda
2022-12-16 04:21:53,198 [DEBUG] Training model: supertest
2022-12-16 04:21:54,541 [DEBUG] Training from 2006, 2006
2022-12-16 04:21:54,569 [DEBUG] [+] Creating LSTM model
2022-12-16 04:21:54,570 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:21:54,570 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0368, validation loss : 0.0487
[2/3] Train loss : 0.0724, validation loss : 0.1390
[3/3] Train loss : 0.0857, validation loss : 0.1390
2022-12-16 04:22:03,948 [DEBUG] [+] Creating Transformer Encoder model
2022-12-16 04:22:03,962 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:22:03,963 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0799, validation loss : 0.1390
[2/5] Train loss : 0.0857, validation loss : 0.1390
[3/5] Train loss : 0.0857, validation loss : 0.1390
[4/5] Train loss : 0.0857, validation loss : 0.1390
[5/5] Train loss : 0.0857, validation loss : 0.1390
2022-12-16 04:23:22,443 [DEBUG] Training from 2007, 2007
2022-12-16 04:23:22,463 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:23:22,464 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1149, validation loss : 0.0525
[2/3] Train loss : 0.1149, validation loss : 0.0525
[3/3] Train loss : 0.1149, validation loss : 0.0525
2022-12-16 04:23:33,670 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:23:33,670 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1149, validation loss : 0.0525
[2/5] Train loss : 0.1149, validation loss : 0.0525
[3/5] Train loss : 0.1149, validation loss : 0.0525
[4/5] Train loss : 0.1149, validation loss : 0.0525
[5/5] Train loss : 0.1149, validation loss : 0.0525
2022-12-16 04:25:51,947 [DEBUG] Training from 2008, 2008
2022-12-16 04:25:51,969 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:25:51,969 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0597, validation loss : -0.1342
[2/3] Train loss : -0.0597, validation loss : -0.1342
[3/3] Train loss : -0.0597, validation loss : -0.1342
2022-12-16 04:26:03,688 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:26:03,689 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0597, validation loss : -0.1342
[2/5] Train loss : -0.0597, validation loss : -0.1342
[3/5] Train loss : -0.0597, validation loss : -0.1342
[4/5] Train loss : -0.0597, validation loss : -0.1342
[5/5] Train loss : -0.0597, validation loss : -0.1342
2022-12-16 04:27:20,175 [DEBUG] Training from 2009, 2009
2022-12-16 04:27:20,190 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:27:20,190 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0290, validation loss : 0.1288
[2/3] Train loss : 0.0290, validation loss : 0.1288
[3/3] Train loss : 0.0290, validation loss : 0.1288
2022-12-16 04:27:31,921 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:27:31,922 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0290, validation loss : 0.1288
[2/5] Train loss : 0.0290, validation loss : 0.1288
[3/5] Train loss : 0.0290, validation loss : 0.1288
[4/5] Train loss : 0.0290, validation loss : 0.1288
[5/5] Train loss : 0.0290, validation loss : 0.1288
2022-12-16 04:28:46,939 [DEBUG] Training from 2010, 2010
2022-12-16 04:28:46,954 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:28:46,954 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0602, validation loss : 0.1834
[2/3] Train loss : 0.0602, validation loss : 0.1834
[3/3] Train loss : 0.0602, validation loss : 0.1834
2022-12-16 04:28:58,853 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:28:58,854 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0602, validation loss : 0.1834
[2/5] Train loss : 0.0602, validation loss : 0.1834
[3/5] Train loss : 0.0602, validation loss : 0.1834
[4/5] Train loss : 0.0602, validation loss : 0.1834
[5/5] Train loss : 0.0602, validation loss : 0.1834
2022-12-16 04:30:14,405 [DEBUG] Training from 2011, 2011
2022-12-16 04:30:14,427 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:30:14,427 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0618, validation loss : -0.0278
[2/3] Train loss : 0.0618, validation loss : -0.0278
[3/3] Train loss : 0.0618, validation loss : -0.0278
2022-12-16 04:30:27,377 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:30:27,378 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0618, validation loss : -0.0278
[2/5] Train loss : 0.0618, validation loss : -0.0278
[3/5] Train loss : 0.0618, validation loss : -0.0278
[4/5] Train loss : 0.0618, validation loss : -0.0278
[5/5] Train loss : 0.0618, validation loss : -0.0278
2022-12-16 04:31:53,659 [DEBUG] Training from 2012, 2012
2022-12-16 04:31:53,680 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:31:53,681 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0309, validation loss : 0.0376
[2/3] Train loss : 0.0309, validation loss : 0.0376
[3/3] Train loss : 0.0309, validation loss : 0.0376
2022-12-16 04:32:07,829 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:32:07,830 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0309, validation loss : 0.0376
[2/5] Train loss : 0.0309, validation loss : 0.0376
[3/5] Train loss : 0.0309, validation loss : 0.0376
[4/5] Train loss : 0.0309, validation loss : 0.0376
[5/5] Train loss : 0.0309, validation loss : 0.0376
2022-12-16 04:33:24,072 [DEBUG] Training from 2013, 2013
2022-12-16 04:33:24,093 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:33:24,093 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0982, validation loss : 0.1321
[2/3] Train loss : 0.0982, validation loss : 0.1321
[3/3] Train loss : 0.0982, validation loss : 0.1321
2022-12-16 04:33:37,031 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:33:37,032 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0982, validation loss : 0.1321
[2/5] Train loss : 0.0982, validation loss : 0.1321
[3/5] Train loss : 0.0982, validation loss : 0.1321
[4/5] Train loss : 0.0982, validation loss : 0.1321
[5/5] Train loss : 0.0982, validation loss : 0.1321
2022-12-16 04:34:52,810 [DEBUG] Training from 2014, 2014
2022-12-16 04:34:52,826 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:34:52,826 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0378, validation loss : 0.0214
[2/3] Train loss : 0.0378, validation loss : 0.0214
[3/3] Train loss : 0.0378, validation loss : 0.0214
2022-12-16 04:35:05,728 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:35:05,729 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0378, validation loss : 0.0214
[2/5] Train loss : 0.0378, validation loss : 0.0214
[3/5] Train loss : 0.0378, validation loss : 0.0214
[4/5] Train loss : 0.0378, validation loss : 0.0214
[5/5] Train loss : 0.0378, validation loss : 0.0214
2022-12-16 04:36:33,430 [DEBUG] Training from 2015, 2015
2022-12-16 04:36:33,451 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:36:33,451 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0324, validation loss : -0.0627
[2/3] Train loss : -0.0324, validation loss : -0.0627
[3/3] Train loss : -0.0324, validation loss : -0.0627
2022-12-16 04:36:46,641 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:36:46,642 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0324, validation loss : -0.0627
[2/5] Train loss : -0.0324, validation loss : -0.0627
[3/5] Train loss : -0.0324, validation loss : -0.0627
[4/5] Train loss : -0.0324, validation loss : -0.0627
[5/5] Train loss : -0.0324, validation loss : -0.0627
2022-12-16 04:38:07,500 [DEBUG] Training from 2016, 2016
2022-12-16 04:38:07,516 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:38:07,516 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0393, validation loss : 0.0433
[2/3] Train loss : 0.0393, validation loss : 0.0433
[3/3] Train loss : 0.0393, validation loss : 0.0433
2022-12-16 04:38:19,941 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:38:19,942 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0393, validation loss : 0.0433
[2/5] Train loss : 0.0393, validation loss : 0.0433
[3/5] Train loss : 0.0393, validation loss : 0.0433
[4/5] Train loss : 0.0393, validation loss : 0.0433
[5/5] Train loss : 0.0393, validation loss : 0.0433
2022-12-16 04:39:37,757 [DEBUG] Training from 2017, 2017
2022-12-16 04:39:37,775 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:39:37,775 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0577, validation loss : 0.1061
[2/3] Train loss : 0.0577, validation loss : 0.1061
[3/3] Train loss : 0.0577, validation loss : 0.1061
2022-12-16 04:39:50,684 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:39:50,685 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0577, validation loss : 0.1061
[2/5] Train loss : 0.0577, validation loss : 0.1061
[3/5] Train loss : 0.0577, validation loss : 0.1061
[4/5] Train loss : 0.0577, validation loss : 0.1061
[5/5] Train loss : 0.0577, validation loss : 0.1061
2022-12-16 04:41:07,614 [DEBUG] Training from 2018, 2018
2022-12-16 04:41:07,637 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:41:07,637 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0171, validation loss : 0.0024
[2/3] Train loss : 0.0171, validation loss : 0.0024
[3/3] Train loss : 0.0171, validation loss : 0.0024
2022-12-16 04:41:20,494 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:41:20,496 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0171, validation loss : 0.0024
[2/5] Train loss : 0.0171, validation loss : 0.0024
[3/5] Train loss : 0.0171, validation loss : 0.0024
[4/5] Train loss : 0.0171, validation loss : 0.0024
[5/5] Train loss : 0.0171, validation loss : 0.0024
2022-12-16 04:42:39,031 [DEBUG] Training from 2019, 2019
2022-12-16 04:42:39,053 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:42:39,053 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0575, validation loss : 0.0367
[2/3] Train loss : 0.0575, validation loss : 0.0367
[3/3] Train loss : 0.0575, validation loss : 0.0367
2022-12-16 04:42:52,347 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:42:52,348 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0575, validation loss : 0.0367
[2/5] Train loss : 0.0575, validation loss : 0.0367
[3/5] Train loss : 0.0575, validation loss : 0.0367
[4/5] Train loss : 0.0575, validation loss : 0.0367
[5/5] Train loss : 0.0575, validation loss : 0.0367
2022-12-16 04:44:11,854 [DEBUG] Training from 2020, 2020
2022-12-16 04:44:11,873 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:44:11,874 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1345, validation loss : 0.1344
[2/3] Train loss : 0.1345, validation loss : 0.1344
[3/3] Train loss : 0.1345, validation loss : 0.1344
2022-12-16 04:44:25,426 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:44:25,427 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1345, validation loss : 0.1344
[2/5] Train loss : 0.1345, validation loss : 0.1344
[3/5] Train loss : 0.1345, validation loss : 0.1344
[4/5] Train loss : 0.1345, validation loss : 0.1344
[5/5] Train loss : 0.1345, validation loss : 0.1344
2022-12-16 04:45:52,604 [DEBUG] Training from 2021, 2021
2022-12-16 04:45:52,621 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:45:52,622 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0863, validation loss : 0.0994
[2/3] Train loss : 0.0863, validation loss : 0.0994
[3/3] Train loss : 0.0863, validation loss : 0.0994
2022-12-16 04:46:06,915 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:46:06,916 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0863, validation loss : 0.0994
[2/5] Train loss : 0.0863, validation loss : 0.0994
[3/5] Train loss : 0.0863, validation loss : 0.0994
[4/5] Train loss : 0.0863, validation loss : 0.0994
[5/5] Train loss : 0.0863, validation loss : 0.0994
2022-12-16 04:47:33,094 [DEBUG] Backtesting strategies
2022-12-16 04:47:33,111 [DEBUG] First year: 2007
2022-12-16 04:47:33,116 [DEBUG] First year: 2007
2022-12-16 04:47:40,396 [DEBUG] Changing year: 2008
2022-12-16 04:47:40,397 [DEBUG] Changing model: lstm - 0
2022-12-16 04:47:40,408 [DEBUG] Changing year: 2008
2022-12-16 04:47:40,409 [DEBUG] Changing model: transformer - 0
2022-12-16 04:47:48,902 [DEBUG] Changing year: 2009
2022-12-16 04:47:48,902 [DEBUG] Changing model: lstm - 1
2022-12-16 04:47:48,910 [DEBUG] Changing year: 2009
2022-12-16 04:47:48,910 [DEBUG] Changing model: transformer - 1
2022-12-16 04:47:58,038 [DEBUG] Changing year: 2010
2022-12-16 04:47:58,038 [DEBUG] Changing model: lstm - 2
2022-12-16 04:47:58,044 [DEBUG] Changing year: 2010
2022-12-16 04:47:58,045 [DEBUG] Changing model: transformer - 2
2022-12-16 04:48:07,495 [DEBUG] Changing year: 2011
2022-12-16 04:48:07,495 [DEBUG] Changing model: lstm - 3
2022-12-16 04:48:07,505 [DEBUG] Changing year: 2011
2022-12-16 04:48:07,505 [DEBUG] Changing model: transformer - 3
2022-12-16 04:48:16,791 [DEBUG] Changing year: 2012
2022-12-16 04:48:16,791 [DEBUG] Changing model: lstm - 4
2022-12-16 04:48:16,801 [DEBUG] Changing year: 2012
2022-12-16 04:48:16,801 [DEBUG] Changing model: transformer - 4
2022-12-16 04:48:25,228 [DEBUG] Changing year: 2013
2022-12-16 04:48:25,228 [DEBUG] Changing model: lstm - 5
2022-12-16 04:48:25,235 [DEBUG] Changing year: 2013
2022-12-16 04:48:25,235 [DEBUG] Changing model: transformer - 5
2022-12-16 04:48:33,366 [DEBUG] Changing year: 2014
2022-12-16 04:48:33,366 [DEBUG] Changing model: lstm - 6
2022-12-16 04:48:33,377 [DEBUG] Changing year: 2014
2022-12-16 04:48:33,377 [DEBUG] Changing model: transformer - 6
2022-12-16 04:48:41,914 [DEBUG] Changing year: 2015
2022-12-16 04:48:41,914 [DEBUG] Changing model: lstm - 7
2022-12-16 04:48:41,921 [DEBUG] Changing year: 2015
2022-12-16 04:48:41,921 [DEBUG] Changing model: transformer - 7
2022-12-16 04:48:50,599 [DEBUG] Changing year: 2016
2022-12-16 04:48:50,600 [DEBUG] Changing model: lstm - 8
2022-12-16 04:48:50,611 [DEBUG] Changing year: 2016
2022-12-16 04:48:50,612 [DEBUG] Changing model: transformer - 8
2022-12-16 04:48:59,192 [DEBUG] Changing year: 2017
2022-12-16 04:48:59,192 [DEBUG] Changing model: lstm - 9
2022-12-16 04:48:59,198 [DEBUG] Changing year: 2017
2022-12-16 04:48:59,198 [DEBUG] Changing model: transformer - 9
2022-12-16 04:49:07,410 [DEBUG] Changing year: 2018
2022-12-16 04:49:07,410 [DEBUG] Changing model: lstm - 10
2022-12-16 04:49:07,415 [DEBUG] Changing year: 2018
2022-12-16 04:49:07,416 [DEBUG] Changing model: transformer - 10
2022-12-16 04:49:15,522 [DEBUG] Changing year: 2019
2022-12-16 04:49:15,523 [DEBUG] Changing model: lstm - 11
2022-12-16 04:49:15,528 [DEBUG] Changing year: 2019
2022-12-16 04:49:15,529 [DEBUG] Changing model: transformer - 11
2022-12-16 04:49:23,816 [DEBUG] Changing year: 2020
2022-12-16 04:49:23,817 [DEBUG] Changing model: lstm - 12
2022-12-16 04:49:23,826 [DEBUG] Changing year: 2020
2022-12-16 04:49:23,826 [DEBUG] Changing model: transformer - 12
2022-12-16 04:49:32,089 [DEBUG] Changing year: 2021
2022-12-16 04:49:32,089 [DEBUG] Changing model: lstm - 13
2022-12-16 04:49:32,096 [DEBUG] Changing year: 2021
2022-12-16 04:49:32,097 [DEBUG] Changing model: transformer - 13
2022-12-16 04:49:40,205 [DEBUG] Changing year: 2022
2022-12-16 04:49:40,205 [DEBUG] Changing model: lstm - 14
2022-12-16 04:49:40,211 [DEBUG] Changing year: 2022
2022-12-16 04:49:40,211 [DEBUG] Changing model: transformer - 14
2022-12-16 04:49:46,334 [DEBUG] Backtesting results
2022-12-16 04:49:46,334 [DEBUG] ---------------------------------
2022-12-16 04:49:46,334 [DEBUG] Results of strategy: random
2022-12-16 04:49:46,335 [DEBUG] Expected returns: 26.362358009379992%
2022-12-16 04:49:46,335 [DEBUG] Volatilty: 39.390668930068436%
2022-12-16 04:49:46,335 [DEBUG] Sharpe Ratio: 0.669253879800365
2022-12-16 04:49:46,335 [DEBUG] MDD: -1.4168355752545625
2022-12-16 04:49:46,335 [DEBUG] ---------------------------------
2022-12-16 04:49:46,335 [DEBUG] Results of strategy: equal strategy
2022-12-16 04:49:46,337 [DEBUG] Expected returns: 21.588841823031302%
2022-12-16 04:49:46,337 [DEBUG] Volatilty: 27.859662298324245%
2022-12-16 04:49:46,337 [DEBUG] Sharpe Ratio: 0.7749139810761406
2022-12-16 04:49:46,337 [DEBUG] MDD: -1.2121061373370512
2022-12-16 04:49:46,337 [DEBUG] ---------------------------------
2022-12-16 04:49:46,337 [DEBUG] Results of strategy: lstm
2022-12-16 04:49:46,338 [DEBUG] Expected returns: 17.50055379111452%
2022-12-16 04:49:46,338 [DEBUG] Volatilty: 12.235491376857127%
2022-12-16 04:49:46,338 [DEBUG] Sharpe Ratio: 1.430310663633503
2022-12-16 04:49:46,338 [DEBUG] MDD: -1.3611001328999937
2022-12-16 04:49:46,338 [DEBUG] ---------------------------------
2022-12-16 04:49:46,339 [DEBUG] Results of strategy: transformer
2022-12-16 04:49:46,340 [DEBUG] Expected returns: 17.46307806728049%
2022-12-16 04:49:46,341 [DEBUG] Volatilty: 12.235023300784054%
2022-12-16 04:49:46,341 [DEBUG] Sharpe Ratio: 1.4273023955877067
2022-12-16 04:49:46,343 [DEBUG] MDD: -1.3611000594342777
2022-12-16 04:49:46,390 [DEBUG] Saving results
2022-12-16 04:49:46,716 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,716 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,716 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,716 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,716 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-16 04:49:46,721 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,722 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,722 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,722 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,722 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-16 04:49:46,771 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,771 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,771 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,771 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,771 [DEBUG] STREAM b'IDAT' 78 374
2022-12-16 04:49:46,773 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,773 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,774 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,774 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,774 [DEBUG] STREAM b'IDAT' 78 286
2022-12-16 04:49:46,776 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,776 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,776 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,776 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,777 [DEBUG] STREAM b'IDAT' 78 263
2022-12-16 04:49:46,779 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,779 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,779 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,779 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,779 [DEBUG] STREAM b'IDAT' 78 387
2022-12-16 04:49:46,781 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,781 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,781 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,781 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,781 [DEBUG] STREAM b'IDAT' 78 436
2022-12-16 04:49:46,783 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,783 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,783 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,783 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,784 [DEBUG] STREAM b'IDAT' 78 351
2022-12-16 04:49:46,785 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 04:49:46,785 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 04:49:46,785 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 04:49:46,785 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 04:49:46,786 [DEBUG] STREAM b'IDAT' 78 364
2022-12-16 04:49:47,302 [DEBUG] Saving models
