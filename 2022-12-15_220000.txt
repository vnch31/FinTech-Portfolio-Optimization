2022-12-15 22:48:10,399 [DEBUG] use config:config.json
2022-12-15 22:48:10,399 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-15 22:48:10,399 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 2 year with 50 days

2022-12-15 22:48:10,400 [DEBUG] Getting data
2022-12-15 22:48:10,400 [DEBUG] Fetch data using the following parameters:
2022-12-15 22:48:10,400 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-15 22:48:10,400 [DEBUG] Start date: 2006-01-01
2022-12-15 22:48:10,400 [DEBUG] End date: 2022-10-01
2022-12-15 22:48:10,400 [DEBUG] Interval: 1d
2022-12-15 22:48:10,400 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-15 22:48:10,417 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-15 22:48:10,449 [DEBUG] Training and testing with the device: cuda
2022-12-15 22:48:10,449 [DEBUG] Training model: supertest
2022-12-15 22:48:11,773 [DEBUG] Training from 2006, 2007
2022-12-15 22:48:11,805 [DEBUG] [+] Creating LSTM model
2022-12-15 22:48:11,816 [DEBUG] [+] Setting sgd optimizer
2022-12-15 22:48:11,816 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0384, validation loss : 0.0659
[2/3] Train loss : 0.0601, validation loss : 0.0659
[3/3] Train loss : 0.0601, validation loss : 0.0659
2022-12-15 22:53:48,597 [DEBUG] [+] Creating TCN model
2022-12-15 22:53:48,622 [DEBUG] [+] Setting sgd optimizer
2022-12-15 22:53:48,625 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0547, validation loss : 0.0659
[2/3] Train loss : 0.0601, validation loss : 0.0659
[3/3] Train loss : 0.0601, validation loss : 0.0659
2022-12-15 22:54:19,487 [DEBUG] [+] Creating RNN model
2022-12-15 22:54:19,499 [DEBUG] [+] Setting sgd optimizer
2022-12-15 22:54:19,501 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1527, validation loss : 0.0901
[2/3] Train loss : 0.1364, validation loss : 0.1330
[3/3] Train loss : 0.1616, validation loss : 0.1148
2022-12-15 22:57:28,317 [DEBUG] [+] Creating GRU model
2022-12-15 22:57:28,478 [DEBUG] [+] Setting sgd optimizer
2022-12-15 22:57:28,482 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1451, validation loss : 0.1020
[2/3] Train loss : 0.1592, validation loss : 0.1291
[3/3] Train loss : 0.1682, validation loss : 0.1340
2022-12-15 23:07:56,223 [DEBUG] [+] Creating Transformer Encoder model
2022-12-15 23:07:56,229 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:07:56,230 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0551, validation loss : 0.0665
[2/3] Train loss : 0.0603, validation loss : 0.0659
[3/3] Train loss : 0.0601, validation loss : 0.0661
2022-12-15 23:08:04,086 [DEBUG] Training from 2008, 2009
2022-12-15 23:08:04,113 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:08:04,114 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0515, validation loss : 0.0983
[2/3] Train loss : -0.0515, validation loss : 0.0983
[3/3] Train loss : -0.0515, validation loss : 0.0983
2022-12-15 23:10:41,130 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:10:41,131 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0515, validation loss : 0.0983
[2/3] Train loss : -0.0515, validation loss : 0.0983
[3/3] Train loss : -0.0515, validation loss : 0.0983
2022-12-15 23:10:45,895 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:10:45,895 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0115, validation loss : 0.1121
[2/3] Train loss : 0.0188, validation loss : 0.1115
[3/3] Train loss : 0.0189, validation loss : 0.1113
2022-12-15 23:11:10,157 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:11:10,157 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0156, validation loss : -0.0261
[2/3] Train loss : -0.0065, validation loss : -0.0259
[3/3] Train loss : -0.0064, validation loss : -0.0257
2022-12-15 23:12:54,843 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:12:54,844 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0515, validation loss : 0.0992
[2/3] Train loss : -0.0514, validation loss : 0.0983
[3/3] Train loss : -0.0445, validation loss : 0.0697
2022-12-15 23:13:02,868 [DEBUG] Training from 2010, 2011
2022-12-15 23:13:02,890 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:13:02,890 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0423, validation loss : -0.0350
[2/3] Train loss : 0.0423, validation loss : -0.0350
[3/3] Train loss : 0.0423, validation loss : -0.0350
2022-12-15 23:14:55,750 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:14:55,751 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0423, validation loss : -0.0350
[2/3] Train loss : 0.0423, validation loss : -0.0350
[3/3] Train loss : 0.0423, validation loss : -0.0350
2022-12-15 23:15:00,625 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:15:00,626 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0995, validation loss : 0.0312
[2/3] Train loss : 0.1172, validation loss : 0.0551
[3/3] Train loss : 0.1313, validation loss : 0.0555
2022-12-15 23:15:23,835 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:15:23,835 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0202, validation loss : -0.0383
[2/3] Train loss : 0.0581, validation loss : 0.0123
[3/3] Train loss : 0.1319, validation loss : 0.0549
2022-12-15 23:17:08,565 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:17:08,565 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0299, validation loss : -0.0399
[2/3] Train loss : 0.0488, validation loss : -0.0733
[3/3] Train loss : 0.0518, validation loss : -0.0683
2022-12-15 23:17:15,520 [DEBUG] Training from 2012, 2013
2022-12-15 23:17:15,541 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:17:15,541 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0153, validation loss : 0.0429
[2/3] Train loss : 0.0153, validation loss : 0.0429
[3/3] Train loss : 0.0153, validation loss : 0.0429
2022-12-15 23:19:07,875 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:19:07,875 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0153, validation loss : 0.0429
[2/3] Train loss : 0.0153, validation loss : 0.0429
[3/3] Train loss : 0.0153, validation loss : 0.0429
2022-12-15 23:19:13,223 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:19:13,224 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1324, validation loss : 0.1395
[2/3] Train loss : 0.1630, validation loss : 0.0452
[3/3] Train loss : 0.1408, validation loss : 0.1708
2022-12-15 23:19:37,683 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:19:37,684 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1501, validation loss : 0.1318
[2/3] Train loss : 0.1381, validation loss : 0.1553
[3/3] Train loss : 0.1575, validation loss : 0.1688
2022-12-15 23:21:32,931 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:21:32,931 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0224, validation loss : 0.0429
[2/3] Train loss : 0.0153, validation loss : 0.0429
[3/3] Train loss : 0.0153, validation loss : 0.0429
2022-12-15 23:21:40,718 [DEBUG] Training from 2014, 2015
2022-12-15 23:21:40,739 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:21:40,740 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0090, validation loss : -0.0582
[2/3] Train loss : 0.0090, validation loss : -0.0582
[3/3] Train loss : 0.0090, validation loss : -0.0582
2022-12-15 23:23:39,722 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:23:39,722 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0090, validation loss : -0.0582
[2/3] Train loss : 0.0090, validation loss : -0.0582
[3/3] Train loss : 0.0090, validation loss : -0.0582
2022-12-15 23:23:46,887 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:23:46,887 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1618, validation loss : 0.0583
[2/3] Train loss : 0.1572, validation loss : 0.0584
[3/3] Train loss : 0.1578, validation loss : 0.0586
2022-12-15 23:24:14,845 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:24:14,846 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1595, validation loss : 0.0582
[2/3] Train loss : 0.1554, validation loss : 0.0583
[3/3] Train loss : 0.1568, validation loss : 0.0584
2022-12-15 23:26:25,769 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:26:25,770 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0090, validation loss : -0.0582
[2/3] Train loss : 0.0090, validation loss : -0.0582
[3/3] Train loss : 0.0090, validation loss : -0.0582
2022-12-15 23:26:37,533 [DEBUG] Training from 2016, 2017
2022-12-15 23:26:37,554 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:26:37,555 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0106, validation loss : 0.0688
[2/3] Train loss : 0.0106, validation loss : 0.0688
[3/3] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 23:29:03,325 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:29:03,326 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0106, validation loss : 0.0688
[2/3] Train loss : 0.0106, validation loss : 0.0688
[3/3] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 23:29:10,821 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:29:10,822 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1263, validation loss : 0.4200
[2/3] Train loss : 0.1328, validation loss : 0.4206
[3/3] Train loss : 0.1340, validation loss : 0.4139
2022-12-15 23:29:45,571 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:29:45,571 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1240, validation loss : 0.4179
[2/3] Train loss : 0.1335, validation loss : 0.4218
[3/3] Train loss : 0.1335, validation loss : 0.4190
2022-12-15 23:32:09,330 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:32:09,331 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0106, validation loss : 0.0688
[2/3] Train loss : 0.0106, validation loss : 0.0688
[3/3] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 23:32:17,963 [DEBUG] Training from 2018, 2019
2022-12-15 23:32:17,987 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:32:17,987 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0201, validation loss : -0.0108
[2/3] Train loss : 0.0201, validation loss : -0.0108
[3/3] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 23:34:50,901 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:34:50,902 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0201, validation loss : -0.0108
[2/3] Train loss : 0.0201, validation loss : -0.0108
[3/3] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 23:34:58,167 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:34:58,167 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0153, validation loss : -0.0460
[2/3] Train loss : 0.0561, validation loss : 0.2298
[3/3] Train loss : 0.0639, validation loss : 0.2301
2022-12-15 23:35:33,650 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:35:33,651 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0459, validation loss : 0.2259
[2/3] Train loss : 0.0393, validation loss : 0.2308
[3/3] Train loss : 0.0542, validation loss : 0.2330
2022-12-15 23:38:13,674 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:38:13,675 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0201, validation loss : -0.0108
[2/3] Train loss : 0.0201, validation loss : -0.0108
[3/3] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 23:38:23,258 [DEBUG] Training from 2020, 2021
2022-12-15 23:38:23,284 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:38:23,285 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0758, validation loss : 0.0579
[2/3] Train loss : 0.0758, validation loss : 0.0579
[3/3] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 23:40:50,146 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:40:50,147 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0758, validation loss : 0.0579
[2/3] Train loss : 0.0758, validation loss : 0.0579
[3/3] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 23:41:04,054 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:41:04,055 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0539, validation loss : 0.0004
[2/3] Train loss : -0.0050, validation loss : 0.0006
[3/3] Train loss : 0.1071, validation loss : 0.1467
2022-12-15 23:41:34,485 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:41:34,486 [DEBUG] [+] Training model...
[1/3] Train loss : 0.2016, validation loss : 0.1568
[2/3] Train loss : 0.2123, validation loss : 0.1548
[3/3] Train loss : 0.2150, validation loss : 0.1427
2022-12-15 23:44:10,409 [DEBUG] [+] Setting sgd optimizer
2022-12-15 23:44:10,409 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0758, validation loss : 0.0579
[2/3] Train loss : 0.0758, validation loss : 0.0579
[3/3] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 23:44:21,198 [DEBUG] Backtesting strategies
2022-12-15 23:44:21,214 [DEBUG] First year: 2008
2022-12-15 23:44:21,270 [DEBUG] First year: 2008
2022-12-15 23:44:21,277 [DEBUG] First year: 2008
2022-12-15 23:44:21,290 [DEBUG] First year: 2008
2022-12-15 23:44:21,348 [DEBUG] First year: 2008
2022-12-15 23:44:46,300 [DEBUG] Changing year: 2009
2022-12-15 23:44:46,333 [DEBUG] Changing year: 2009
2022-12-15 23:44:46,338 [DEBUG] Changing year: 2009
2022-12-15 23:44:46,345 [DEBUG] Changing year: 2009
2022-12-15 23:44:46,380 [DEBUG] Changing year: 2009
2022-12-15 23:45:18,162 [DEBUG] Changing year: 2010
2022-12-15 23:45:18,162 [DEBUG] Changing model: lstm - 0
2022-12-15 23:45:18,239 [DEBUG] Changing year: 2010
2022-12-15 23:45:18,243 [DEBUG] Changing model: tcn - 0
2022-12-15 23:45:18,250 [DEBUG] Changing year: 2010
2022-12-15 23:45:18,252 [DEBUG] Changing model: rnn - 0
2022-12-15 23:45:18,263 [DEBUG] Changing year: 2010
2022-12-15 23:45:18,266 [DEBUG] Changing model: gru - 0
2022-12-15 23:45:18,331 [DEBUG] Changing year: 2010
2022-12-15 23:45:18,332 [DEBUG] Changing model: transformer - 0
2022-12-15 23:45:49,752 [DEBUG] Changing year: 2011
2022-12-15 23:45:49,790 [DEBUG] Changing year: 2011
2022-12-15 23:45:49,795 [DEBUG] Changing year: 2011
2022-12-15 23:45:49,804 [DEBUG] Changing year: 2011
2022-12-15 23:45:49,850 [DEBUG] Changing year: 2011
2022-12-15 23:46:15,202 [DEBUG] Changing year: 2012
2022-12-15 23:46:15,202 [DEBUG] Changing model: lstm - 1
2022-12-15 23:46:15,244 [DEBUG] Changing year: 2012
2022-12-15 23:46:15,245 [DEBUG] Changing model: tcn - 1
2022-12-15 23:46:15,248 [DEBUG] Changing year: 2012
2022-12-15 23:46:15,248 [DEBUG] Changing model: rnn - 1
2022-12-15 23:46:15,255 [DEBUG] Changing year: 2012
2022-12-15 23:46:15,256 [DEBUG] Changing model: gru - 1
2022-12-15 23:46:15,297 [DEBUG] Changing year: 2012
2022-12-15 23:46:15,298 [DEBUG] Changing model: transformer - 1
2022-12-15 23:46:45,038 [DEBUG] Changing year: 2013
2022-12-15 23:46:45,087 [DEBUG] Changing year: 2013
2022-12-15 23:46:45,092 [DEBUG] Changing year: 2013
2022-12-15 23:46:45,104 [DEBUG] Changing year: 2013
2022-12-15 23:46:45,187 [DEBUG] Changing year: 2013
2022-12-15 23:47:13,962 [DEBUG] Changing year: 2014
2022-12-15 23:47:13,963 [DEBUG] Changing model: lstm - 2
2022-12-15 23:47:14,012 [DEBUG] Changing year: 2014
2022-12-15 23:47:14,014 [DEBUG] Changing model: tcn - 2
2022-12-15 23:47:14,019 [DEBUG] Changing year: 2014
2022-12-15 23:47:14,020 [DEBUG] Changing model: rnn - 2
2022-12-15 23:47:14,033 [DEBUG] Changing year: 2014
2022-12-15 23:47:14,034 [DEBUG] Changing model: gru - 2
2022-12-15 23:47:14,090 [DEBUG] Changing year: 2014
2022-12-15 23:47:14,096 [DEBUG] Changing model: transformer - 2
2022-12-15 23:47:47,047 [DEBUG] Changing year: 2015
2022-12-15 23:47:47,083 [DEBUG] Changing year: 2015
2022-12-15 23:47:47,088 [DEBUG] Changing year: 2015
2022-12-15 23:47:47,095 [DEBUG] Changing year: 2015
2022-12-15 23:47:47,138 [DEBUG] Changing year: 2015
2022-12-15 23:48:12,957 [DEBUG] Changing year: 2016
2022-12-15 23:48:12,957 [DEBUG] Changing model: lstm - 3
2022-12-15 23:48:12,990 [DEBUG] Changing year: 2016
2022-12-15 23:48:12,992 [DEBUG] Changing model: tcn - 3
2022-12-15 23:48:12,995 [DEBUG] Changing year: 2016
2022-12-15 23:48:12,995 [DEBUG] Changing model: rnn - 3
2022-12-15 23:48:13,001 [DEBUG] Changing year: 2016
2022-12-15 23:48:13,002 [DEBUG] Changing model: gru - 3
2022-12-15 23:48:13,034 [DEBUG] Changing year: 2016
2022-12-15 23:48:13,036 [DEBUG] Changing model: transformer - 3
2022-12-15 23:48:38,560 [DEBUG] Changing year: 2017
2022-12-15 23:48:38,598 [DEBUG] Changing year: 2017
2022-12-15 23:48:38,602 [DEBUG] Changing year: 2017
2022-12-15 23:48:38,610 [DEBUG] Changing year: 2017
2022-12-15 23:48:38,650 [DEBUG] Changing year: 2017
2022-12-15 23:49:06,367 [DEBUG] Changing year: 2018
2022-12-15 23:49:06,370 [DEBUG] Changing model: lstm - 4
2022-12-15 23:49:06,418 [DEBUG] Changing year: 2018
2022-12-15 23:49:06,420 [DEBUG] Changing model: tcn - 4
2022-12-15 23:49:06,424 [DEBUG] Changing year: 2018
2022-12-15 23:49:06,425 [DEBUG] Changing model: rnn - 4
2022-12-15 23:49:06,434 [DEBUG] Changing year: 2018
2022-12-15 23:49:06,435 [DEBUG] Changing model: gru - 4
2022-12-15 23:49:06,509 [DEBUG] Changing year: 2018
2022-12-15 23:49:06,512 [DEBUG] Changing model: transformer - 4
2022-12-15 23:49:31,951 [DEBUG] Changing year: 2019
2022-12-15 23:49:31,990 [DEBUG] Changing year: 2019
2022-12-15 23:49:31,994 [DEBUG] Changing year: 2019
2022-12-15 23:49:32,001 [DEBUG] Changing year: 2019
2022-12-15 23:49:32,033 [DEBUG] Changing year: 2019
2022-12-15 23:49:53,679 [DEBUG] Changing year: 2020
2022-12-15 23:49:53,679 [DEBUG] Changing model: lstm - 5
2022-12-15 23:49:53,723 [DEBUG] Changing year: 2020
2022-12-15 23:49:53,726 [DEBUG] Changing model: tcn - 5
2022-12-15 23:49:53,729 [DEBUG] Changing year: 2020
2022-12-15 23:49:53,729 [DEBUG] Changing model: rnn - 5
2022-12-15 23:49:53,737 [DEBUG] Changing year: 2020
2022-12-15 23:49:53,738 [DEBUG] Changing model: gru - 5
2022-12-15 23:49:53,779 [DEBUG] Changing year: 2020
2022-12-15 23:49:53,781 [DEBUG] Changing model: transformer - 5
2022-12-15 23:50:16,871 [DEBUG] Changing year: 2021
2022-12-15 23:50:16,909 [DEBUG] Changing year: 2021
2022-12-15 23:50:16,915 [DEBUG] Changing year: 2021
2022-12-15 23:50:16,922 [DEBUG] Changing year: 2021
2022-12-15 23:50:16,964 [DEBUG] Changing year: 2021
2022-12-15 23:50:39,223 [DEBUG] Changing year: 2022
2022-12-15 23:50:39,223 [DEBUG] Changing model: lstm - 6
2022-12-15 23:50:39,255 [DEBUG] Changing year: 2022
2022-12-15 23:50:39,256 [DEBUG] Changing model: tcn - 6
2022-12-15 23:50:39,259 [DEBUG] Changing year: 2022
2022-12-15 23:50:39,260 [DEBUG] Changing model: rnn - 6
2022-12-15 23:50:39,267 [DEBUG] Changing year: 2022
2022-12-15 23:50:39,267 [DEBUG] Changing model: gru - 6
2022-12-15 23:50:39,299 [DEBUG] Changing year: 2022
2022-12-15 23:50:39,301 [DEBUG] Changing model: transformer - 6
2022-12-15 23:50:55,230 [DEBUG] Backtesting results
2022-12-15 23:50:55,230 [DEBUG] ---------------------------------
2022-12-15 23:50:55,231 [DEBUG] Results of strategy: random
2022-12-15 23:50:55,232 [DEBUG] Expected returns: 21.08864456626462%
2022-12-15 23:50:55,232 [DEBUG] Volatilty: 35.198465569863465%
2022-12-15 23:50:55,232 [DEBUG] Sharpe Ratio: 0.5991353379995201
2022-12-15 23:50:55,233 [DEBUG] MDD: -1.5004892182259986
2022-12-15 23:50:55,233 [DEBUG] ---------------------------------
2022-12-15 23:50:55,233 [DEBUG] Results of strategy: equal strategy
2022-12-15 23:50:55,234 [DEBUG] Expected returns: 19.099810829319914%
2022-12-15 23:50:55,235 [DEBUG] Volatilty: 27.671778722561047%
2022-12-15 23:50:55,235 [DEBUG] Sharpe Ratio: 0.6902270728895237
2022-12-15 23:50:55,236 [DEBUG] MDD: -1.2121061373370512
2022-12-15 23:50:55,236 [DEBUG] ---------------------------------
2022-12-15 23:50:55,236 [DEBUG] Results of strategy: lstm
2022-12-15 23:50:55,237 [DEBUG] Expected returns: 17.83542315885066%
2022-12-15 23:50:55,238 [DEBUG] Volatilty: 15.711628339196634%
2022-12-15 23:50:55,238 [DEBUG] Sharpe Ratio: 1.135173438029697
2022-12-15 23:50:55,239 [DEBUG] MDD: -1.2536962667254739
2022-12-15 23:50:55,239 [DEBUG] ---------------------------------
2022-12-15 23:50:55,239 [DEBUG] Results of strategy: tcn
2022-12-15 23:50:55,240 [DEBUG] Expected returns: 17.83542437832513%
2022-12-15 23:50:55,241 [DEBUG] Volatilty: 15.711628319392338%
2022-12-15 23:50:55,241 [DEBUG] Sharpe Ratio: 1.135173517076614
2022-12-15 23:50:55,241 [DEBUG] MDD: -1.2536963009590165
2022-12-15 23:50:55,241 [DEBUG] ---------------------------------
2022-12-15 23:50:55,241 [DEBUG] Results of strategy: rnn
2022-12-15 23:50:55,243 [DEBUG] Expected returns: 8.732908773278078%
2022-12-15 23:50:55,243 [DEBUG] Volatilty: 8.899429228712927%
2022-12-15 23:50:55,243 [DEBUG] Sharpe Ratio: 0.9812886364782146
2022-12-15 23:50:55,243 [DEBUG] MDD: -1.7520261655333782
2022-12-15 23:50:55,243 [DEBUG] ---------------------------------
2022-12-15 23:50:55,244 [DEBUG] Results of strategy: gru
2022-12-15 23:50:55,244 [DEBUG] Expected returns: 8.093039047631287%
2022-12-15 23:50:55,244 [DEBUG] Volatilty: 7.555886337222841%
2022-12-15 23:50:55,244 [DEBUG] Sharpe Ratio: 1.071090628740966
2022-12-15 23:50:55,245 [DEBUG] MDD: -1.7631358757260946
2022-12-15 23:50:55,245 [DEBUG] ---------------------------------
2022-12-15 23:50:55,246 [DEBUG] Results of strategy: transformer
2022-12-15 23:50:55,247 [DEBUG] Expected returns: 17.83542266649361%
2022-12-15 23:50:55,247 [DEBUG] Volatilty: 15.711628119362404%
2022-12-15 23:50:55,247 [DEBUG] Sharpe Ratio: 1.1351734225757244
2022-12-15 23:50:55,248 [DEBUG] MDD: -1.2536962775881497
2022-12-15 23:50:55,364 [DEBUG] Saving results
2022-12-15 23:50:55,657 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,658 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,658 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,658 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,658 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-15 23:50:55,663 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,663 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,663 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,663 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,663 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-15 23:50:55,708 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,708 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,708 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,708 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,709 [DEBUG] STREAM b'IDAT' 78 374
2022-12-15 23:50:55,710 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,710 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,711 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,711 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,711 [DEBUG] STREAM b'IDAT' 78 286
2022-12-15 23:50:55,712 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,712 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,712 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,713 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,713 [DEBUG] STREAM b'IDAT' 78 263
2022-12-15 23:50:55,714 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,714 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,714 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,715 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,715 [DEBUG] STREAM b'IDAT' 78 387
2022-12-15 23:50:55,716 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,716 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,717 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,717 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,717 [DEBUG] STREAM b'IDAT' 78 436
2022-12-15 23:50:55,718 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,718 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,718 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,718 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,719 [DEBUG] STREAM b'IDAT' 78 351
2022-12-15 23:50:55,720 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 23:50:55,720 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 23:50:55,720 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 23:50:55,720 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 23:50:55,720 [DEBUG] STREAM b'IDAT' 78 364
2022-12-15 23:50:56,406 [DEBUG] Saving models
