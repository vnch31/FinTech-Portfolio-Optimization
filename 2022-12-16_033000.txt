2022-12-16 03:30:48,942 [DEBUG] use config:config.json
2022-12-16 03:30:48,942 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-16 03:30:48,942 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 2 year with 30 days

2022-12-16 03:30:48,942 [DEBUG] Getting data
2022-12-16 03:30:48,942 [DEBUG] Fetch data using the following parameters:
2022-12-16 03:30:48,942 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-16 03:30:48,942 [DEBUG] Start date: 2006-01-01
2022-12-16 03:30:48,942 [DEBUG] End date: 2022-10-01
2022-12-16 03:30:48,942 [DEBUG] Interval: 1d
2022-12-16 03:30:48,942 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-16 03:30:48,960 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-16 03:30:49,013 [DEBUG] Training and testing with the device: cuda
2022-12-16 03:30:49,013 [DEBUG] Training model: supertest
2022-12-16 03:30:50,436 [DEBUG] Training from 2006, 2007
2022-12-16 03:30:50,469 [DEBUG] [+] Creating LSTM model
2022-12-16 03:30:50,470 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:30:50,470 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0369, validation loss : 0.0381
[2/3] Train loss : 0.0863, validation loss : 0.0463
[3/3] Train loss : 0.0986, validation loss : 0.0463
2022-12-16 03:31:00,853 [DEBUG] [+] Creating Transformer Encoder model
2022-12-16 03:31:00,872 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:31:00,873 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0443, validation loss : 0.0463
[2/5] Train loss : 0.0986, validation loss : 0.0463
[3/5] Train loss : 0.0986, validation loss : 0.0463
[4/5] Train loss : 0.0986, validation loss : 0.0463
[5/5] Train loss : 0.0985, validation loss : 0.0463
2022-12-16 03:32:16,138 [DEBUG] Training from 2008, 2009
2022-12-16 03:32:16,153 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:32:16,153 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0636, validation loss : 0.1288
[2/3] Train loss : -0.0636, validation loss : 0.1288
[3/3] Train loss : -0.0636, validation loss : 0.1288
2022-12-16 03:32:27,578 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:32:27,580 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0636, validation loss : 0.1288
[2/5] Train loss : -0.0636, validation loss : 0.1288
[3/5] Train loss : -0.0636, validation loss : 0.1288
[4/5] Train loss : -0.0636, validation loss : 0.1288
[5/5] Train loss : -0.0636, validation loss : 0.1288
2022-12-16 03:34:21,004 [DEBUG] Training from 2010, 2011
2022-12-16 03:34:21,022 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:34:21,023 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0822, validation loss : -0.0278
[2/3] Train loss : 0.0822, validation loss : -0.0278
[3/3] Train loss : 0.0822, validation loss : -0.0278
2022-12-16 03:34:36,399 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:34:36,401 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0822, validation loss : -0.0278
[2/5] Train loss : 0.0822, validation loss : -0.0278
[3/5] Train loss : 0.0821, validation loss : -0.0278
[4/5] Train loss : 0.0823, validation loss : -0.0278
[5/5] Train loss : 0.0822, validation loss : -0.0278
2022-12-16 03:35:55,599 [DEBUG] Training from 2012, 2013
2022-12-16 03:35:55,614 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:35:55,614 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0540, validation loss : 0.1327
[2/3] Train loss : 0.0540, validation loss : 0.1327
[3/3] Train loss : 0.0540, validation loss : 0.1327
2022-12-16 03:36:08,403 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:36:08,404 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0540, validation loss : 0.1328
[2/5] Train loss : 0.0540, validation loss : 0.1327
[3/5] Train loss : 0.0540, validation loss : 0.1327
[4/5] Train loss : 0.0539, validation loss : 0.1327
[5/5] Train loss : 0.0540, validation loss : 0.1327
2022-12-16 03:37:31,714 [DEBUG] Training from 2014, 2015
2022-12-16 03:37:31,729 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:37:31,729 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0171, validation loss : -0.0627
[2/3] Train loss : 0.0171, validation loss : -0.0627
[3/3] Train loss : 0.0171, validation loss : -0.0627
2022-12-16 03:37:44,936 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:37:44,938 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0171, validation loss : -0.0627
[2/5] Train loss : 0.0171, validation loss : -0.0627
[3/5] Train loss : 0.0170, validation loss : -0.0627
[4/5] Train loss : 0.0171, validation loss : -0.0627
[5/5] Train loss : 0.0171, validation loss : -0.0627
2022-12-16 03:39:02,504 [DEBUG] Training from 2016, 2017
2022-12-16 03:39:02,521 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:39:02,521 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0333, validation loss : 0.1052
[2/3] Train loss : 0.0333, validation loss : 0.1052
[3/3] Train loss : 0.0333, validation loss : 0.1052
2022-12-16 03:39:15,612 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:39:15,613 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0333, validation loss : 0.1052
[2/5] Train loss : 0.0333, validation loss : 0.1052
[3/5] Train loss : 0.0333, validation loss : 0.1052
[4/5] Train loss : 0.0333, validation loss : 0.1052
[5/5] Train loss : 0.0333, validation loss : 0.1052
2022-12-16 03:40:39,411 [DEBUG] Training from 2018, 2019
2022-12-16 03:40:39,427 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:40:39,427 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0314, validation loss : 0.0367
[2/3] Train loss : 0.0314, validation loss : 0.0367
[3/3] Train loss : 0.0314, validation loss : 0.0367
2022-12-16 03:40:53,045 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:40:53,046 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0314, validation loss : 0.0367
[2/5] Train loss : 0.0314, validation loss : 0.0367
[3/5] Train loss : 0.0314, validation loss : 0.0367
[4/5] Train loss : 0.0314, validation loss : 0.0367
[5/5] Train loss : 0.0314, validation loss : 0.0367
2022-12-16 03:42:13,955 [DEBUG] Training from 2020, 2021
2022-12-16 03:42:13,980 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:42:13,981 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1250, validation loss : 0.0994
[2/3] Train loss : 0.1250, validation loss : 0.0994
[3/3] Train loss : 0.1250, validation loss : 0.0994
2022-12-16 03:42:27,129 [DEBUG] [+] Setting sgd optimizer
2022-12-16 03:42:27,130 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1250, validation loss : 0.0994
[2/5] Train loss : 0.1250, validation loss : 0.0994
[3/5] Train loss : 0.1250, validation loss : 0.0994
[4/5] Train loss : 0.1250, validation loss : 0.0994
[5/5] Train loss : 0.1250, validation loss : 0.0994
2022-12-16 03:43:53,816 [DEBUG] Backtesting strategies
2022-12-16 03:43:53,827 [DEBUG] First year: 2008
2022-12-16 03:43:53,832 [DEBUG] First year: 2008
2022-12-16 03:44:01,606 [DEBUG] Changing year: 2009
2022-12-16 03:44:01,616 [DEBUG] Changing year: 2009
2022-12-16 03:44:09,725 [DEBUG] Changing year: 2010
2022-12-16 03:44:09,725 [DEBUG] Changing model: lstm - 0
2022-12-16 03:44:09,731 [DEBUG] Changing year: 2010
2022-12-16 03:44:09,731 [DEBUG] Changing model: transformer - 0
2022-12-16 03:44:17,436 [DEBUG] Changing year: 2011
2022-12-16 03:44:17,446 [DEBUG] Changing year: 2011
2022-12-16 03:44:25,112 [DEBUG] Changing year: 2012
2022-12-16 03:44:25,112 [DEBUG] Changing model: lstm - 1
2022-12-16 03:44:25,117 [DEBUG] Changing year: 2012
2022-12-16 03:44:25,118 [DEBUG] Changing model: transformer - 1
2022-12-16 03:44:32,486 [DEBUG] Changing year: 2013
2022-12-16 03:44:32,491 [DEBUG] Changing year: 2013
2022-12-16 03:44:40,020 [DEBUG] Changing year: 2014
2022-12-16 03:44:40,020 [DEBUG] Changing model: lstm - 2
2022-12-16 03:44:40,029 [DEBUG] Changing year: 2014
2022-12-16 03:44:40,030 [DEBUG] Changing model: transformer - 2
2022-12-16 03:44:47,547 [DEBUG] Changing year: 2015
2022-12-16 03:44:47,556 [DEBUG] Changing year: 2015
2022-12-16 03:44:55,473 [DEBUG] Changing year: 2016
2022-12-16 03:44:55,473 [DEBUG] Changing model: lstm - 3
2022-12-16 03:44:55,479 [DEBUG] Changing year: 2016
2022-12-16 03:44:55,480 [DEBUG] Changing model: transformer - 3
2022-12-16 03:45:03,180 [DEBUG] Changing year: 2017
2022-12-16 03:45:03,191 [DEBUG] Changing year: 2017
2022-12-16 03:45:10,889 [DEBUG] Changing year: 2018
2022-12-16 03:45:10,889 [DEBUG] Changing model: lstm - 4
2022-12-16 03:45:10,895 [DEBUG] Changing year: 2018
2022-12-16 03:45:10,895 [DEBUG] Changing model: transformer - 4
2022-12-16 03:45:18,717 [DEBUG] Changing year: 2019
2022-12-16 03:45:18,725 [DEBUG] Changing year: 2019
2022-12-16 03:45:26,820 [DEBUG] Changing year: 2020
2022-12-16 03:45:26,820 [DEBUG] Changing model: lstm - 5
2022-12-16 03:45:26,827 [DEBUG] Changing year: 2020
2022-12-16 03:45:26,827 [DEBUG] Changing model: transformer - 5
2022-12-16 03:45:34,642 [DEBUG] Changing year: 2021
2022-12-16 03:45:34,648 [DEBUG] Changing year: 2021
2022-12-16 03:45:42,520 [DEBUG] Changing year: 2022
2022-12-16 03:45:42,520 [DEBUG] Changing model: lstm - 6
2022-12-16 03:45:42,531 [DEBUG] Changing year: 2022
2022-12-16 03:45:42,531 [DEBUG] Changing model: transformer - 6
2022-12-16 03:45:48,196 [DEBUG] Backtesting results
2022-12-16 03:45:48,196 [DEBUG] ---------------------------------
2022-12-16 03:45:48,196 [DEBUG] Results of strategy: random
2022-12-16 03:45:48,198 [DEBUG] Expected returns: 16.330929926984336%
2022-12-16 03:45:48,198 [DEBUG] Volatilty: 39.874535268414576%
2022-12-16 03:45:48,198 [DEBUG] Sharpe Ratio: 0.4095578748956704
2022-12-16 03:45:48,199 [DEBUG] MDD: -1.341839329807281
2022-12-16 03:45:48,199 [DEBUG] ---------------------------------
2022-12-16 03:45:48,199 [DEBUG] Results of strategy: equal strategy
2022-12-16 03:45:48,200 [DEBUG] Expected returns: 19.5730706714877%
2022-12-16 03:45:48,200 [DEBUG] Volatilty: 27.640171995858577%
2022-12-16 03:45:48,200 [DEBUG] Sharpe Ratio: 0.7081385265772008
2022-12-16 03:45:48,200 [DEBUG] MDD: -1.2121061373370512
2022-12-16 03:45:48,200 [DEBUG] ---------------------------------
2022-12-16 03:45:48,200 [DEBUG] Results of strategy: lstm
2022-12-16 03:45:48,202 [DEBUG] Expected returns: 16.844039060826123%
2022-12-16 03:45:48,202 [DEBUG] Volatilty: 12.291825812810606%
2022-12-16 03:45:48,202 [DEBUG] Sharpe Ratio: 1.370344757348512
2022-12-16 03:45:48,203 [DEBUG] MDD: -1.3611000594342777
2022-12-16 03:45:48,203 [DEBUG] ---------------------------------
2022-12-16 03:45:48,203 [DEBUG] Results of strategy: transformer
2022-12-16 03:45:48,205 [DEBUG] Expected returns: 16.844037865337754%
2022-12-16 03:45:48,205 [DEBUG] Volatilty: 12.291825557627622%
2022-12-16 03:45:48,205 [DEBUG] Sharpe Ratio: 1.3703446885385775
2022-12-16 03:45:48,206 [DEBUG] MDD: -1.3611001328999937
2022-12-16 03:45:48,237 [DEBUG] Saving results
2022-12-16 03:45:48,535 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,535 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,535 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,535 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,535 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-16 03:45:48,540 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,540 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,540 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,540 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,540 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-16 03:45:48,586 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,586 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,586 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,586 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,586 [DEBUG] STREAM b'IDAT' 78 374
2022-12-16 03:45:48,587 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,588 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,588 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,588 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,588 [DEBUG] STREAM b'IDAT' 78 286
2022-12-16 03:45:48,589 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,589 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,589 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,589 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,589 [DEBUG] STREAM b'IDAT' 78 263
2022-12-16 03:45:48,590 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,590 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,590 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,590 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,591 [DEBUG] STREAM b'IDAT' 78 387
2022-12-16 03:45:48,591 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,592 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,592 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,592 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,592 [DEBUG] STREAM b'IDAT' 78 436
2022-12-16 03:45:48,593 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,593 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,593 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,593 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,593 [DEBUG] STREAM b'IDAT' 78 351
2022-12-16 03:45:48,594 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 03:45:48,594 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 03:45:48,594 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 03:45:48,594 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 03:45:48,594 [DEBUG] STREAM b'IDAT' 78 364
2022-12-16 03:45:49,119 [DEBUG] Saving models
