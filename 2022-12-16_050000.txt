2022-12-16 04:54:34,219 [DEBUG] use config:config.json
2022-12-16 04:54:34,220 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-16 04:54:34,220 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 1 year with 25 days

2022-12-16 04:54:34,220 [DEBUG] Getting data
2022-12-16 04:54:34,220 [DEBUG] Fetch data using the following parameters:
2022-12-16 04:54:34,220 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-16 04:54:34,220 [DEBUG] Start date: 2006-01-01
2022-12-16 04:54:34,220 [DEBUG] End date: 2022-10-01
2022-12-16 04:54:34,220 [DEBUG] Interval: 1d
2022-12-16 04:54:34,220 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-16 04:54:34,237 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-16 04:54:34,267 [DEBUG] Training and testing with the device: cuda
2022-12-16 04:54:34,268 [DEBUG] Training model: supertest
2022-12-16 04:54:35,505 [DEBUG] Training from 2006, 2006
2022-12-16 04:54:35,533 [DEBUG] [+] Creating LSTM model
2022-12-16 04:54:35,534 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:54:35,534 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0360, validation loss : 0.0309
[2/3] Train loss : 0.0587, validation loss : 0.1341
[3/3] Train loss : 0.0874, validation loss : 0.1341
2022-12-16 04:54:43,140 [DEBUG] [+] Creating Transformer Encoder model
2022-12-16 04:54:43,154 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:54:43,154 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0070, validation loss : -0.0461
[2/5] Train loss : 0.0076, validation loss : -0.0461
[3/5] Train loss : 0.0076, validation loss : -0.0461
[4/5] Train loss : 0.0076, validation loss : -0.0459
[5/5] Train loss : 0.0076, validation loss : -0.0461
2022-12-16 04:56:34,234 [DEBUG] Training from 2007, 2007
2022-12-16 04:56:34,345 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:56:34,347 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1176, validation loss : 0.0476
[2/3] Train loss : 0.1176, validation loss : 0.0476
[3/3] Train loss : 0.1176, validation loss : 0.0476
2022-12-16 04:56:57,574 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:56:57,575 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0278, validation loss : -0.0176
[2/5] Train loss : 0.0278, validation loss : -0.0176
[3/5] Train loss : 0.0278, validation loss : -0.0176
[4/5] Train loss : 0.0278, validation loss : -0.0176
[5/5] Train loss : 0.0278, validation loss : -0.0176
2022-12-16 04:58:03,389 [DEBUG] Training from 2008, 2008
2022-12-16 04:58:03,406 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:58:03,407 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0621, validation loss : -0.1273
[2/3] Train loss : -0.0621, validation loss : -0.1273
[3/3] Train loss : -0.0621, validation loss : -0.1273
2022-12-16 04:58:14,128 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:58:14,129 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0044, validation loss : 0.0752
[2/5] Train loss : -0.0053, validation loss : -0.1754
[3/5] Train loss : 0.0109, validation loss : -0.1754
[4/5] Train loss : 0.0109, validation loss : -0.1754
[5/5] Train loss : 0.0109, validation loss : -0.1754
2022-12-16 04:59:25,209 [DEBUG] Training from 2009, 2009
2022-12-16 04:59:25,228 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:59:25,229 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0211, validation loss : 0.1254
[2/3] Train loss : 0.0211, validation loss : 0.1254
[3/3] Train loss : 0.0211, validation loss : 0.1254
2022-12-16 04:59:36,372 [DEBUG] [+] Setting sgd optimizer
2022-12-16 04:59:36,373 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0179, validation loss : 0.0337
[2/5] Train loss : -0.0179, validation loss : 0.0337
[3/5] Train loss : -0.0179, validation loss : 0.0337
[4/5] Train loss : -0.0179, validation loss : 0.0337
[5/5] Train loss : -0.0179, validation loss : 0.0337
2022-12-16 05:00:45,948 [DEBUG] Training from 2010, 2010
2022-12-16 05:00:45,964 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:00:45,965 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0578, validation loss : 0.1888
[2/3] Train loss : 0.0578, validation loss : 0.1888
[3/3] Train loss : 0.0578, validation loss : 0.1888
2022-12-16 05:00:57,022 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:00:57,023 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0013, validation loss : 0.0838
[2/5] Train loss : -0.0013, validation loss : 0.0838
[3/5] Train loss : -0.0013, validation loss : 0.0838
[4/5] Train loss : -0.0013, validation loss : 0.0838
[5/5] Train loss : -0.0013, validation loss : 0.0838
2022-12-16 05:02:10,170 [DEBUG] Training from 2011, 2011
2022-12-16 05:02:10,190 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:02:10,190 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0653, validation loss : -0.0273
[2/3] Train loss : 0.0653, validation loss : -0.0273
[3/3] Train loss : 0.0653, validation loss : -0.0273
2022-12-16 05:02:21,885 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:02:21,887 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0132, validation loss : -0.1504
[2/5] Train loss : 0.0132, validation loss : -0.1504
[3/5] Train loss : 0.0132, validation loss : -0.1504
[4/5] Train loss : 0.0132, validation loss : -0.1504
[5/5] Train loss : 0.0132, validation loss : -0.1504
2022-12-16 05:03:35,910 [DEBUG] Training from 2012, 2012
2022-12-16 05:03:35,926 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:03:35,926 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0348, validation loss : 0.0623
[2/3] Train loss : 0.0348, validation loss : 0.0623
[3/3] Train loss : 0.0348, validation loss : 0.0623
2022-12-16 05:04:00,736 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:04:00,737 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0185, validation loss : 0.0113
[2/5] Train loss : -0.0185, validation loss : 0.0113
[3/5] Train loss : -0.0185, validation loss : 0.0113
[4/5] Train loss : -0.0185, validation loss : 0.0113
[5/5] Train loss : -0.0185, validation loss : 0.0113
2022-12-16 05:05:11,008 [DEBUG] Training from 2013, 2013
2022-12-16 05:05:11,028 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:05:11,028 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1011, validation loss : 0.1442
[2/3] Train loss : 0.1011, validation loss : 0.1442
[3/3] Train loss : 0.1011, validation loss : 0.1442
2022-12-16 05:05:22,731 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:05:22,732 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0111, validation loss : 0.0087
[2/5] Train loss : -0.0111, validation loss : 0.0087
[3/5] Train loss : -0.0111, validation loss : 0.0087
[4/5] Train loss : -0.0111, validation loss : 0.0087
[5/5] Train loss : -0.0111, validation loss : 0.0087
2022-12-16 05:06:34,211 [DEBUG] Training from 2014, 2014
2022-12-16 05:06:34,227 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:06:34,227 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0342, validation loss : 0.0232
[2/3] Train loss : 0.0342, validation loss : 0.0232
[3/3] Train loss : 0.0342, validation loss : 0.0232
2022-12-16 05:06:45,614 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:06:45,615 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0384, validation loss : -0.1232
[2/5] Train loss : -0.0384, validation loss : -0.1232
[3/5] Train loss : -0.0384, validation loss : -0.1232
[4/5] Train loss : -0.0384, validation loss : -0.1232
[5/5] Train loss : -0.0384, validation loss : -0.1232
2022-12-16 05:07:57,989 [DEBUG] Training from 2015, 2015
2022-12-16 05:07:58,005 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:07:58,006 [DEBUG] [+] Training model...
[1/3] Train loss : -0.0362, validation loss : -0.0660
[2/3] Train loss : -0.0362, validation loss : -0.0660
[3/3] Train loss : -0.0362, validation loss : -0.0660
2022-12-16 05:08:08,559 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:08:08,560 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0661, validation loss : -0.1027
[2/5] Train loss : -0.0661, validation loss : -0.1027
[3/5] Train loss : -0.0661, validation loss : -0.1027
[4/5] Train loss : -0.0661, validation loss : -0.1027
[5/5] Train loss : -0.0661, validation loss : -0.1027
2022-12-16 05:09:18,661 [DEBUG] Training from 2016, 2016
2022-12-16 05:09:18,685 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:09:18,685 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0391, validation loss : 0.0555
[2/3] Train loss : 0.0391, validation loss : 0.0555
[3/3] Train loss : 0.0391, validation loss : 0.0555
2022-12-16 05:09:29,693 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:09:29,694 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0237, validation loss : 0.0404
[2/5] Train loss : 0.0237, validation loss : 0.0404
[3/5] Train loss : 0.0237, validation loss : 0.0404
[4/5] Train loss : 0.0237, validation loss : 0.0404
[5/5] Train loss : 0.0237, validation loss : 0.0404
2022-12-16 05:10:39,161 [DEBUG] Training from 2017, 2017
2022-12-16 05:10:39,177 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:10:39,178 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0577, validation loss : 0.1044
[2/3] Train loss : 0.0577, validation loss : 0.1044
[3/3] Train loss : 0.0577, validation loss : 0.1044
2022-12-16 05:10:50,447 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:10:50,449 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0004, validation loss : 0.0517
[2/5] Train loss : -0.0004, validation loss : 0.0517
[3/5] Train loss : -0.0004, validation loss : 0.0517
[4/5] Train loss : -0.0004, validation loss : 0.0517
[5/5] Train loss : -0.0004, validation loss : 0.0517
2022-12-16 05:12:10,764 [DEBUG] Training from 2018, 2018
2022-12-16 05:12:10,784 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:12:10,784 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0135, validation loss : 0.0016
[2/3] Train loss : 0.0135, validation loss : 0.0016
[3/3] Train loss : 0.0135, validation loss : 0.0016
2022-12-16 05:12:21,611 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:12:21,612 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0110, validation loss : 0.0376
[2/5] Train loss : 0.0110, validation loss : 0.0376
[3/5] Train loss : 0.0110, validation loss : 0.0376
[4/5] Train loss : 0.0110, validation loss : 0.0376
[5/5] Train loss : 0.0110, validation loss : 0.0376
2022-12-16 05:13:31,354 [DEBUG] Training from 2019, 2019
2022-12-16 05:13:31,370 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:13:31,371 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0575, validation loss : 0.0392
[2/3] Train loss : 0.0575, validation loss : 0.0392
[3/3] Train loss : 0.0575, validation loss : 0.0392
2022-12-16 05:13:42,304 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:13:42,305 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0138, validation loss : -0.0125
[2/5] Train loss : -0.0138, validation loss : -0.0125
[3/5] Train loss : -0.0138, validation loss : -0.0125
[4/5] Train loss : -0.0138, validation loss : -0.0125
[5/5] Train loss : -0.0138, validation loss : -0.0125
2022-12-16 05:14:51,082 [DEBUG] Training from 2020, 2020
2022-12-16 05:14:51,104 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:14:51,105 [DEBUG] [+] Training model...
[1/3] Train loss : 0.1404, validation loss : 0.1511
[2/3] Train loss : 0.1404, validation loss : 0.1511
[3/3] Train loss : 0.1404, validation loss : 0.1511
2022-12-16 05:15:02,377 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:15:02,378 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0325, validation loss : 0.0702
[2/5] Train loss : 0.0325, validation loss : 0.0702
[3/5] Train loss : 0.0325, validation loss : 0.0702
[4/5] Train loss : 0.0325, validation loss : 0.0702
[5/5] Train loss : 0.0325, validation loss : 0.0702
2022-12-16 05:16:12,022 [DEBUG] Training from 2021, 2021
2022-12-16 05:16:12,044 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:16:12,045 [DEBUG] [+] Training model...
[1/3] Train loss : 0.0900, validation loss : 0.1048
[2/3] Train loss : 0.0900, validation loss : 0.1048
[3/3] Train loss : 0.0900, validation loss : 0.1048
2022-12-16 05:16:23,154 [DEBUG] [+] Setting sgd optimizer
2022-12-16 05:16:23,155 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0568, validation loss : 0.0751
[2/5] Train loss : 0.0568, validation loss : 0.0751
[3/5] Train loss : 0.0568, validation loss : 0.0751
[4/5] Train loss : 0.0568, validation loss : 0.0751
[5/5] Train loss : 0.0568, validation loss : 0.0751
2022-12-16 05:17:33,121 [DEBUG] Backtesting strategies
2022-12-16 05:17:33,131 [DEBUG] First year: 2007
2022-12-16 05:17:33,135 [DEBUG] First year: 2007
2022-12-16 05:17:39,482 [DEBUG] Changing year: 2008
2022-12-16 05:17:39,482 [DEBUG] Changing model: lstm - 0
2022-12-16 05:17:39,487 [DEBUG] Changing year: 2008
2022-12-16 05:17:39,487 [DEBUG] Changing model: transformer - 0
2022-12-16 05:17:46,479 [DEBUG] Changing year: 2009
2022-12-16 05:17:46,479 [DEBUG] Changing model: lstm - 1
2022-12-16 05:17:46,484 [DEBUG] Changing year: 2009
2022-12-16 05:17:46,484 [DEBUG] Changing model: transformer - 1
2022-12-16 05:17:53,159 [DEBUG] Changing year: 2010
2022-12-16 05:17:53,159 [DEBUG] Changing model: lstm - 2
2022-12-16 05:17:53,167 [DEBUG] Changing year: 2010
2022-12-16 05:17:53,168 [DEBUG] Changing model: transformer - 2
2022-12-16 05:17:59,893 [DEBUG] Changing year: 2011
2022-12-16 05:17:59,893 [DEBUG] Changing model: lstm - 3
2022-12-16 05:17:59,899 [DEBUG] Changing year: 2011
2022-12-16 05:17:59,899 [DEBUG] Changing model: transformer - 3
2022-12-16 05:18:06,735 [DEBUG] Changing year: 2012
2022-12-16 05:18:06,736 [DEBUG] Changing model: lstm - 4
2022-12-16 05:18:06,741 [DEBUG] Changing year: 2012
2022-12-16 05:18:06,741 [DEBUG] Changing model: transformer - 4
2022-12-16 05:18:13,441 [DEBUG] Changing year: 2013
2022-12-16 05:18:13,442 [DEBUG] Changing model: lstm - 5
2022-12-16 05:18:13,447 [DEBUG] Changing year: 2013
2022-12-16 05:18:13,447 [DEBUG] Changing model: transformer - 5
2022-12-16 05:18:20,458 [DEBUG] Changing year: 2014
2022-12-16 05:18:20,458 [DEBUG] Changing model: lstm - 6
2022-12-16 05:18:20,464 [DEBUG] Changing year: 2014
2022-12-16 05:18:20,464 [DEBUG] Changing model: transformer - 6
2022-12-16 05:18:27,431 [DEBUG] Changing year: 2015
2022-12-16 05:18:27,431 [DEBUG] Changing model: lstm - 7
2022-12-16 05:18:27,436 [DEBUG] Changing year: 2015
2022-12-16 05:18:27,436 [DEBUG] Changing model: transformer - 7
2022-12-16 05:18:34,287 [DEBUG] Changing year: 2016
2022-12-16 05:18:34,288 [DEBUG] Changing model: lstm - 8
2022-12-16 05:18:34,294 [DEBUG] Changing year: 2016
2022-12-16 05:18:34,294 [DEBUG] Changing model: transformer - 8
2022-12-16 05:18:41,498 [DEBUG] Changing year: 2017
2022-12-16 05:18:41,498 [DEBUG] Changing model: lstm - 9
2022-12-16 05:18:41,507 [DEBUG] Changing year: 2017
2022-12-16 05:18:41,508 [DEBUG] Changing model: transformer - 9
2022-12-16 05:18:48,711 [DEBUG] Changing year: 2018
2022-12-16 05:18:48,711 [DEBUG] Changing model: lstm - 10
2022-12-16 05:18:48,719 [DEBUG] Changing year: 2018
2022-12-16 05:18:48,719 [DEBUG] Changing model: transformer - 10
2022-12-16 05:18:56,043 [DEBUG] Changing year: 2019
2022-12-16 05:18:56,043 [DEBUG] Changing model: lstm - 11
2022-12-16 05:18:56,050 [DEBUG] Changing year: 2019
2022-12-16 05:18:56,050 [DEBUG] Changing model: transformer - 11
2022-12-16 05:19:16,582 [DEBUG] Changing year: 2020
2022-12-16 05:19:16,582 [DEBUG] Changing model: lstm - 12
2022-12-16 05:19:16,589 [DEBUG] Changing year: 2020
2022-12-16 05:19:16,590 [DEBUG] Changing model: transformer - 12
2022-12-16 05:19:23,159 [DEBUG] Changing year: 2021
2022-12-16 05:19:23,159 [DEBUG] Changing model: lstm - 13
2022-12-16 05:19:23,166 [DEBUG] Changing year: 2021
2022-12-16 05:19:23,166 [DEBUG] Changing model: transformer - 13
2022-12-16 05:19:29,799 [DEBUG] Changing year: 2022
2022-12-16 05:19:29,799 [DEBUG] Changing model: lstm - 14
2022-12-16 05:19:29,805 [DEBUG] Changing year: 2022
2022-12-16 05:19:29,805 [DEBUG] Changing model: transformer - 14
2022-12-16 05:19:34,841 [DEBUG] Backtesting results
2022-12-16 05:19:34,841 [DEBUG] ---------------------------------
2022-12-16 05:19:34,841 [DEBUG] Results of strategy: random
2022-12-16 05:19:34,843 [DEBUG] Expected returns: 14.747068408516363%
2022-12-16 05:19:34,843 [DEBUG] Volatilty: 35.73621850511773%
2022-12-16 05:19:34,843 [DEBUG] Sharpe Ratio: 0.4126644906876326
2022-12-16 05:19:34,843 [DEBUG] MDD: -1.5198973847035624
2022-12-16 05:19:34,844 [DEBUG] ---------------------------------
2022-12-16 05:19:34,844 [DEBUG] Results of strategy: equal strategy
2022-12-16 05:19:34,844 [DEBUG] Expected returns: 21.53744100259779%
2022-12-16 05:19:34,844 [DEBUG] Volatilty: 27.85010109085362%
2022-12-16 05:19:34,845 [DEBUG] Sharpe Ratio: 0.773334392300321
2022-12-16 05:19:34,845 [DEBUG] MDD: -1.2121061373370512
2022-12-16 05:19:34,845 [DEBUG] ---------------------------------
2022-12-16 05:19:34,845 [DEBUG] Results of strategy: lstm
2022-12-16 05:19:34,846 [DEBUG] Expected returns: 17.479160474951673%
2022-12-16 05:19:34,847 [DEBUG] Volatilty: 12.229692377110204%
2022-12-16 05:19:34,847 [DEBUG] Sharpe Ratio: 1.4292395864074778
2022-12-16 05:19:34,847 [DEBUG] MDD: -1.3611002390378164
2022-12-16 05:19:34,847 [DEBUG] ---------------------------------
2022-12-16 05:19:34,847 [DEBUG] Results of strategy: transformer
2022-12-16 05:19:34,849 [DEBUG] Expected returns: 15.955487749824758%
2022-12-16 05:19:34,849 [DEBUG] Volatilty: 19.005368104229508%
2022-12-16 05:19:34,849 [DEBUG] Sharpe Ratio: 0.839525320547408
2022-12-16 05:19:34,850 [DEBUG] MDD: -1.2951055238287768
2022-12-16 05:19:34,891 [DEBUG] Saving results
2022-12-16 05:19:35,185 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,185 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,186 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,186 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,186 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-16 05:19:35,190 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,190 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,190 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,190 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,190 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-16 05:19:35,236 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,237 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,237 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,237 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,237 [DEBUG] STREAM b'IDAT' 78 374
2022-12-16 05:19:35,238 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,239 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,239 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,239 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,239 [DEBUG] STREAM b'IDAT' 78 286
2022-12-16 05:19:35,240 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,240 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,240 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,240 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,241 [DEBUG] STREAM b'IDAT' 78 263
2022-12-16 05:19:35,242 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,242 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,242 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,243 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,243 [DEBUG] STREAM b'IDAT' 78 387
2022-12-16 05:19:35,244 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,244 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,244 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,244 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,244 [DEBUG] STREAM b'IDAT' 78 436
2022-12-16 05:19:35,246 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,246 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,246 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,246 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,246 [DEBUG] STREAM b'IDAT' 78 351
2022-12-16 05:19:35,248 [DEBUG] STREAM b'IHDR' 16 13
2022-12-16 05:19:35,248 [DEBUG] STREAM b'sBIT' 41 4
2022-12-16 05:19:35,248 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-16 05:19:35,248 [DEBUG] STREAM b'pHYs' 57 9
2022-12-16 05:19:35,248 [DEBUG] STREAM b'IDAT' 78 364
2022-12-16 05:19:35,759 [DEBUG] Saving models
