2022-12-15 20:00:32,300 [DEBUG] use config:config.json
2022-12-15 20:00:32,300 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-15 20:00:32,300 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 2 year with 50 days

2022-12-15 20:00:32,300 [DEBUG] Getting data
2022-12-15 20:00:32,301 [DEBUG] Fetch data using the following parameters:
2022-12-15 20:00:32,301 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-15 20:00:32,301 [DEBUG] Start date: 2006-01-01
2022-12-15 20:00:32,301 [DEBUG] End date: 2022-10-01
2022-12-15 20:00:32,301 [DEBUG] Interval: 1d
2022-12-15 20:00:32,301 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-15 20:00:32,322 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-15 20:00:32,352 [DEBUG] Training and testing with the device: cuda
2022-12-15 20:00:32,352 [DEBUG] Training model: supertest
2022-12-15 20:00:33,646 [DEBUG] Training from 2006, 2007
2022-12-15 20:00:33,675 [DEBUG] [+] Creating LSTM model
2022-12-15 20:00:33,679 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:00:33,679 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0415, validation loss : 0.0684
[2/7] Train loss : 0.0514, validation loss : 0.0734
[3/7] Train loss : 0.0529, validation loss : 0.0763
[4/7] Train loss : 0.0539, validation loss : 0.0780
[5/7] Train loss : 0.0547, validation loss : 0.0793
[6/7] Train loss : 0.0552, validation loss : 0.0800
[7/7] Train loss : 0.0557, validation loss : 0.0807
2022-12-15 20:06:50,333 [DEBUG] [+] Creating TCN model
2022-12-15 20:06:50,338 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:06:50,338 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0414, validation loss : 0.0615
[2/7] Train loss : 0.0492, validation loss : 0.0615
[3/7] Train loss : 0.0492, validation loss : 0.0615
[4/7] Train loss : 0.0492, validation loss : 0.0615
[5/7] Train loss : 0.0492, validation loss : 0.0615
[6/7] Train loss : 0.0492, validation loss : 0.0615
[7/7] Train loss : 0.0492, validation loss : 0.0615
2022-12-15 20:07:02,728 [DEBUG] [+] Creating RNN model
2022-12-15 20:07:02,730 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:07:02,731 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1471, validation loss : 0.0804
[2/7] Train loss : 0.1812, validation loss : 0.0891
[3/7] Train loss : 0.1816, validation loss : 0.1108
[4/7] Train loss : 0.1817, validation loss : 0.1229
[5/7] Train loss : 0.1825, validation loss : 0.1214
[6/7] Train loss : 0.1842, validation loss : 0.1207
[7/7] Train loss : 0.1848, validation loss : 0.1213
2022-12-15 20:07:48,325 [DEBUG] [+] Creating GRU model
2022-12-15 20:07:48,330 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:07:48,331 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1465, validation loss : 0.1149
[2/7] Train loss : 0.1850, validation loss : 0.1212
[3/7] Train loss : 0.1822, validation loss : 0.1214
[4/7] Train loss : 0.1838, validation loss : 0.1199
[5/7] Train loss : 0.1850, validation loss : 0.1207
[6/7] Train loss : 0.1856, validation loss : 0.1223
[7/7] Train loss : 0.1861, validation loss : 0.1265
2022-12-15 20:11:38,795 [DEBUG] [+] Creating Transformer Encoder model
2022-12-15 20:11:38,799 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:11:38,799 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0438, validation loss : 0.0615
[2/7] Train loss : 0.0492, validation loss : 0.0617
[3/7] Train loss : 0.0492, validation loss : 0.0618
[4/7] Train loss : 0.0492, validation loss : 0.0617
[5/7] Train loss : 0.0490, validation loss : 0.0615
[6/7] Train loss : 0.0492, validation loss : 0.0615
[7/7] Train loss : 0.0492, validation loss : 0.0615
2022-12-15 20:11:55,154 [DEBUG] Training from 2008, 2009
2022-12-15 20:11:55,175 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:11:55,176 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0349, validation loss : 0.0600
[2/7] Train loss : -0.0266, validation loss : 0.0600
[3/7] Train loss : -0.0266, validation loss : 0.0600
[4/7] Train loss : -0.0266, validation loss : 0.0600
[5/7] Train loss : -0.0266, validation loss : 0.0600
[6/7] Train loss : -0.0266, validation loss : 0.0600
[7/7] Train loss : -0.0266, validation loss : 0.0600
2022-12-15 20:16:44,276 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:16:44,277 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0482, validation loss : 0.0774
[2/7] Train loss : -0.0482, validation loss : 0.0774
[3/7] Train loss : -0.0482, validation loss : 0.0774
[4/7] Train loss : -0.0482, validation loss : 0.0774
[5/7] Train loss : -0.0482, validation loss : 0.0774
[6/7] Train loss : -0.0482, validation loss : 0.0774
[7/7] Train loss : -0.0482, validation loss : 0.0774
2022-12-15 20:16:58,616 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:16:58,617 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0237, validation loss : -0.0100
[2/7] Train loss : -0.0132, validation loss : -0.0103
[3/7] Train loss : -0.0083, validation loss : 0.1190
[4/7] Train loss : 0.0136, validation loss : 0.1169
[5/7] Train loss : 0.0133, validation loss : 0.1169
[6/7] Train loss : 0.0134, validation loss : 0.1169
[7/7] Train loss : 0.0134, validation loss : 0.1169
2022-12-15 20:17:51,575 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:17:51,576 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0389, validation loss : 0.1439
[2/7] Train loss : -0.0269, validation loss : 0.1415
[3/7] Train loss : -0.0263, validation loss : 0.1409
[4/7] Train loss : -0.0262, validation loss : 0.1407
[5/7] Train loss : -0.0261, validation loss : 0.1406
[6/7] Train loss : -0.0260, validation loss : 0.1405
[7/7] Train loss : -0.0260, validation loss : 0.1404
2022-12-15 20:22:24,584 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:22:24,584 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0423, validation loss : 0.0600
[2/7] Train loss : -0.0266, validation loss : 0.0600
[3/7] Train loss : -0.0266, validation loss : 0.0600
[4/7] Train loss : -0.0266, validation loss : 0.0600
[5/7] Train loss : -0.0266, validation loss : 0.0600
[6/7] Train loss : -0.0266, validation loss : 0.0600
[7/7] Train loss : -0.0266, validation loss : 0.0600
2022-12-15 20:22:43,906 [DEBUG] Training from 2010, 2011
2022-12-15 20:22:43,931 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:22:43,932 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0216, validation loss : -0.0763
[2/7] Train loss : 0.0216, validation loss : -0.0763
[3/7] Train loss : 0.0216, validation loss : -0.0763
[4/7] Train loss : 0.0216, validation loss : -0.0763
[5/7] Train loss : 0.0216, validation loss : -0.0763
[6/7] Train loss : 0.0216, validation loss : -0.0763
[7/7] Train loss : 0.0216, validation loss : -0.0763
2022-12-15 20:27:08,677 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:27:08,677 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0298, validation loss : -0.0422
[2/7] Train loss : 0.0298, validation loss : -0.0422
[3/7] Train loss : 0.0298, validation loss : -0.0422
[4/7] Train loss : 0.0298, validation loss : -0.0422
[5/7] Train loss : 0.0298, validation loss : -0.0422
[6/7] Train loss : 0.0298, validation loss : -0.0422
[7/7] Train loss : 0.0298, validation loss : -0.0422
2022-12-15 20:27:22,975 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:27:22,975 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0773, validation loss : -0.0289
[2/7] Train loss : 0.1165, validation loss : 0.0427
[3/7] Train loss : 0.1479, validation loss : 0.0438
[4/7] Train loss : 0.1494, validation loss : 0.0438
[5/7] Train loss : 0.1504, validation loss : 0.0441
[6/7] Train loss : 0.1515, validation loss : 0.0439
[7/7] Train loss : 0.1515, validation loss : 0.0439
2022-12-15 20:28:15,254 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:28:15,255 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1071, validation loss : 0.0402
[2/7] Train loss : 0.1104, validation loss : 0.0416
[3/7] Train loss : 0.1466, validation loss : 0.0438
[4/7] Train loss : 0.1511, validation loss : 0.0437
[5/7] Train loss : 0.1508, validation loss : 0.0437
[6/7] Train loss : 0.1504, validation loss : 0.0436
[7/7] Train loss : 0.1501, validation loss : 0.0437
2022-12-15 20:32:59,481 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:32:59,482 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0216, validation loss : -0.0763
[2/7] Train loss : 0.0216, validation loss : -0.0763
[3/7] Train loss : 0.0216, validation loss : -0.0763
[4/7] Train loss : 0.0216, validation loss : -0.0763
[5/7] Train loss : 0.0216, validation loss : -0.0763
[6/7] Train loss : 0.0216, validation loss : -0.0763
[7/7] Train loss : 0.0216, validation loss : -0.0763
2022-12-15 20:33:19,348 [DEBUG] Training from 2012, 2013
2022-12-15 20:33:19,376 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:33:19,376 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0197, validation loss : -0.0138
[2/7] Train loss : -0.0197, validation loss : -0.0138
[3/7] Train loss : -0.0197, validation loss : -0.0138
[4/7] Train loss : -0.0197, validation loss : -0.0138
[5/7] Train loss : -0.0197, validation loss : -0.0138
[6/7] Train loss : -0.0197, validation loss : -0.0138
[7/7] Train loss : -0.0197, validation loss : -0.0138
2022-12-15 20:37:32,990 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:37:32,990 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0053, validation loss : 0.0288
[2/7] Train loss : 0.0053, validation loss : 0.0288
[3/7] Train loss : 0.0053, validation loss : 0.0288
[4/7] Train loss : 0.0053, validation loss : 0.0288
[5/7] Train loss : 0.0053, validation loss : 0.0288
[6/7] Train loss : 0.0053, validation loss : 0.0288
[7/7] Train loss : 0.0053, validation loss : 0.0288
2022-12-15 20:37:44,838 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:37:44,839 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1090, validation loss : 0.1663
[2/7] Train loss : 0.1489, validation loss : 0.1738
[3/7] Train loss : 0.1553, validation loss : 0.1777
[4/7] Train loss : 0.1560, validation loss : 0.1793
[5/7] Train loss : 0.1559, validation loss : 0.1825
[6/7] Train loss : 0.1561, validation loss : 0.1874
[7/7] Train loss : 0.1560, validation loss : 0.1938
2022-12-15 20:38:27,938 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:38:27,939 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1570, validation loss : 0.1836
[2/7] Train loss : 0.1549, validation loss : 0.1869
[3/7] Train loss : 0.1554, validation loss : 0.1908
[4/7] Train loss : 0.1557, validation loss : 0.1953
[5/7] Train loss : 0.1559, validation loss : 0.2000
[6/7] Train loss : 0.1561, validation loss : 0.2058
[7/7] Train loss : 0.1563, validation loss : 0.2107
2022-12-15 20:42:15,751 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:42:15,751 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0197, validation loss : -0.0138
[2/7] Train loss : -0.0197, validation loss : -0.0138
[3/7] Train loss : -0.0197, validation loss : -0.0138
[4/7] Train loss : -0.0197, validation loss : -0.0138
[5/7] Train loss : -0.0197, validation loss : -0.0138
[6/7] Train loss : -0.0197, validation loss : -0.0138
[7/7] Train loss : -0.0197, validation loss : -0.0138
2022-12-15 20:42:31,039 [DEBUG] Training from 2014, 2015
2022-12-15 20:42:31,060 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:42:31,061 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0271, validation loss : -0.0877
[2/7] Train loss : -0.0271, validation loss : -0.0877
[3/7] Train loss : -0.0271, validation loss : -0.0877
[4/7] Train loss : -0.0271, validation loss : -0.0877
[5/7] Train loss : -0.0271, validation loss : -0.0877
[6/7] Train loss : -0.0271, validation loss : -0.0877
[7/7] Train loss : -0.0271, validation loss : -0.0877
2022-12-15 20:46:13,829 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:46:13,829 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0035, validation loss : -0.0598
[2/7] Train loss : 0.0035, validation loss : -0.0598
[3/7] Train loss : 0.0035, validation loss : -0.0598
[4/7] Train loss : 0.0035, validation loss : -0.0598
[5/7] Train loss : 0.0035, validation loss : -0.0598
[6/7] Train loss : 0.0035, validation loss : -0.0598
[7/7] Train loss : 0.0035, validation loss : -0.0598
2022-12-15 20:46:25,620 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:46:25,620 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1240, validation loss : 0.0240
[2/7] Train loss : 0.1187, validation loss : 0.0239
[3/7] Train loss : 0.1195, validation loss : 0.0234
[4/7] Train loss : 0.1202, validation loss : 0.0229
[5/7] Train loss : 0.1208, validation loss : 0.0225
[6/7] Train loss : 0.1214, validation loss : 0.0219
[7/7] Train loss : 0.1220, validation loss : 0.0214
2022-12-15 20:47:11,276 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:47:11,276 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1245, validation loss : 0.0236
[2/7] Train loss : 0.1199, validation loss : 0.0232
[3/7] Train loss : 0.1206, validation loss : 0.0228
[4/7] Train loss : 0.1212, validation loss : 0.0223
[5/7] Train loss : 0.1218, validation loss : 0.0217
[6/7] Train loss : 0.1222, validation loss : 0.0211
[7/7] Train loss : 0.1226, validation loss : 0.0205
2022-12-15 20:51:05,487 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:51:05,487 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0271, validation loss : -0.0877
[2/7] Train loss : -0.0271, validation loss : -0.0877
[3/7] Train loss : -0.0271, validation loss : -0.0877
[4/7] Train loss : -0.0271, validation loss : -0.0877
[5/7] Train loss : -0.0271, validation loss : -0.0877
[6/7] Train loss : -0.0271, validation loss : -0.0877
[7/7] Train loss : -0.0271, validation loss : -0.0877
2022-12-15 20:51:20,268 [DEBUG] Training from 2016, 2017
2022-12-15 20:51:20,287 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:51:20,288 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0049, validation loss : 0.0561
[2/7] Train loss : -0.0049, validation loss : 0.0561
[3/7] Train loss : -0.0049, validation loss : 0.0561
[4/7] Train loss : -0.0049, validation loss : 0.0561
[5/7] Train loss : -0.0049, validation loss : 0.0561
[6/7] Train loss : -0.0049, validation loss : 0.0561
[7/7] Train loss : -0.0049, validation loss : 0.0561
2022-12-15 20:54:49,014 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:54:49,015 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0048, validation loss : 0.0563
[2/7] Train loss : 0.0048, validation loss : 0.0563
[3/7] Train loss : 0.0048, validation loss : 0.0563
[4/7] Train loss : 0.0048, validation loss : 0.0563
[5/7] Train loss : 0.0048, validation loss : 0.0563
[6/7] Train loss : 0.0048, validation loss : 0.0563
[7/7] Train loss : 0.0048, validation loss : 0.0563
2022-12-15 20:55:00,353 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:55:00,354 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1217, validation loss : 0.3910
[2/7] Train loss : 0.1177, validation loss : 0.3964
[3/7] Train loss : 0.1178, validation loss : 0.4014
[4/7] Train loss : 0.1182, validation loss : 0.4069
[5/7] Train loss : 0.1186, validation loss : 0.4114
[6/7] Train loss : 0.1193, validation loss : 0.4153
[7/7] Train loss : 0.1197, validation loss : 0.4180
2022-12-15 20:55:41,604 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:55:41,605 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1232, validation loss : 0.3957
[2/7] Train loss : 0.1182, validation loss : 0.4014
[3/7] Train loss : 0.1187, validation loss : 0.4066
[4/7] Train loss : 0.1192, validation loss : 0.4109
[5/7] Train loss : 0.1196, validation loss : 0.4145
[6/7] Train loss : 0.1201, validation loss : 0.4177
[7/7] Train loss : 0.1205, validation loss : 0.4201
2022-12-15 20:59:15,011 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:59:15,012 [DEBUG] [+] Training model...
[1/7] Train loss : -0.0049, validation loss : 0.0561
[2/7] Train loss : -0.0049, validation loss : 0.0561
[3/7] Train loss : -0.0049, validation loss : 0.0561
[4/7] Train loss : -0.0049, validation loss : 0.0561
[5/7] Train loss : -0.0049, validation loss : 0.0561
[6/7] Train loss : -0.0049, validation loss : 0.0561
[7/7] Train loss : -0.0049, validation loss : 0.0561
2022-12-15 20:59:31,177 [DEBUG] Training from 2018, 2019
2022-12-15 20:59:31,198 [DEBUG] [+] Setting sgd optimizer
2022-12-15 20:59:31,199 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0064, validation loss : -0.0271
[2/7] Train loss : 0.0064, validation loss : -0.0271
[3/7] Train loss : 0.0064, validation loss : -0.0271
[4/7] Train loss : 0.0064, validation loss : -0.0271
[5/7] Train loss : 0.0064, validation loss : -0.0271
[6/7] Train loss : 0.0064, validation loss : -0.0271
[7/7] Train loss : 0.0064, validation loss : -0.0271
2022-12-15 21:03:03,671 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:03:03,671 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0157, validation loss : -0.0205
[2/7] Train loss : 0.0157, validation loss : -0.0205
[3/7] Train loss : 0.0157, validation loss : -0.0205
[4/7] Train loss : 0.0157, validation loss : -0.0205
[5/7] Train loss : 0.0157, validation loss : -0.0205
[6/7] Train loss : 0.0157, validation loss : -0.0205
[7/7] Train loss : 0.0157, validation loss : -0.0205
2022-12-15 21:03:15,345 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:03:15,345 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0845, validation loss : 0.0219
[2/7] Train loss : 0.0662, validation loss : 0.1352
[3/7] Train loss : 0.0169, validation loss : -0.0470
[4/7] Train loss : 0.0567, validation loss : 0.0558
[5/7] Train loss : 0.1218, validation loss : 0.1891
[6/7] Train loss : 0.1323, validation loss : 0.1909
[7/7] Train loss : 0.1331, validation loss : 0.1928
2022-12-15 21:03:58,064 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:03:58,064 [DEBUG] [+] Training model...
[1/7] Train loss : 0.1040, validation loss : 0.1998
[2/7] Train loss : 0.1279, validation loss : 0.1888
[3/7] Train loss : 0.1315, validation loss : 0.1895
[4/7] Train loss : 0.1323, validation loss : 0.1913
[5/7] Train loss : 0.1330, validation loss : 0.1933
[6/7] Train loss : 0.1336, validation loss : 0.1951
[7/7] Train loss : 0.1341, validation loss : 0.1967
2022-12-15 21:07:37,106 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:07:37,107 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0064, validation loss : -0.0271
[2/7] Train loss : 0.0064, validation loss : -0.0271
[3/7] Train loss : 0.0064, validation loss : -0.0271
[4/7] Train loss : 0.0064, validation loss : -0.0271
[5/7] Train loss : 0.0064, validation loss : -0.0271
[6/7] Train loss : 0.0064, validation loss : -0.0271
[7/7] Train loss : 0.0064, validation loss : -0.0271
2022-12-15 21:07:51,893 [DEBUG] Training from 2020, 2021
2022-12-15 21:07:51,915 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:07:51,915 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0441, validation loss : 0.0565
[2/7] Train loss : 0.0441, validation loss : 0.0565
[3/7] Train loss : 0.0441, validation loss : 0.0565
[4/7] Train loss : 0.0441, validation loss : 0.0565
[5/7] Train loss : 0.0441, validation loss : 0.0565
[6/7] Train loss : 0.0441, validation loss : 0.0565
[7/7] Train loss : 0.0441, validation loss : 0.0565
2022-12-15 21:11:38,377 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:11:38,377 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0609, validation loss : 0.0488
[2/7] Train loss : 0.0609, validation loss : 0.0488
[3/7] Train loss : 0.0609, validation loss : 0.0488
[4/7] Train loss : 0.0609, validation loss : 0.0488
[5/7] Train loss : 0.0609, validation loss : 0.0488
[6/7] Train loss : 0.0609, validation loss : 0.0488
[7/7] Train loss : 0.0609, validation loss : 0.0488
2022-12-15 21:11:50,523 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:11:50,524 [DEBUG] [+] Training model...
[1/7] Train loss : 0.2130, validation loss : 0.1449
[2/7] Train loss : 0.2155, validation loss : 0.1470
[3/7] Train loss : 0.2143, validation loss : 0.1470
[4/7] Train loss : 0.2133, validation loss : 0.1471
[5/7] Train loss : 0.2123, validation loss : 0.1471
[6/7] Train loss : 0.2117, validation loss : 0.1471
[7/7] Train loss : 0.2113, validation loss : 0.1471
2022-12-15 21:12:35,364 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:12:35,365 [DEBUG] [+] Training model...
[1/7] Train loss : 0.2134, validation loss : 0.1433
[2/7] Train loss : 0.2156, validation loss : 0.1471
[3/7] Train loss : 0.2134, validation loss : 0.1470
[4/7] Train loss : 0.2125, validation loss : 0.1470
[5/7] Train loss : 0.2119, validation loss : 0.1470
[6/7] Train loss : 0.2115, validation loss : 0.1470
[7/7] Train loss : 0.2111, validation loss : 0.1470
2022-12-15 21:16:14,974 [DEBUG] [+] Setting sgd optimizer
2022-12-15 21:16:14,975 [DEBUG] [+] Training model...
[1/7] Train loss : 0.0441, validation loss : 0.0565
[2/7] Train loss : 0.0441, validation loss : 0.0565
[3/7] Train loss : 0.0441, validation loss : 0.0565
[4/7] Train loss : 0.0441, validation loss : 0.0565
[5/7] Train loss : 0.0441, validation loss : 0.0565
[6/7] Train loss : 0.0441, validation loss : 0.0565
[7/7] Train loss : 0.0441, validation loss : 0.0565
2022-12-15 21:16:31,364 [DEBUG] Backtesting strategies
2022-12-15 21:16:31,377 [DEBUG] First year: 2008
2022-12-15 21:16:31,405 [DEBUG] First year: 2008
2022-12-15 21:16:31,409 [DEBUG] First year: 2008
2022-12-15 21:16:31,414 [DEBUG] First year: 2008
2022-12-15 21:16:31,440 [DEBUG] First year: 2008
2022-12-15 21:16:45,757 [DEBUG] Changing year: 2009
2022-12-15 21:16:45,791 [DEBUG] Changing year: 2009
2022-12-15 21:16:45,795 [DEBUG] Changing year: 2009
2022-12-15 21:16:45,801 [DEBUG] Changing year: 2009
2022-12-15 21:16:45,828 [DEBUG] Changing year: 2009
2022-12-15 21:17:03,742 [DEBUG] Changing year: 2010
2022-12-15 21:17:03,742 [DEBUG] Changing model: lstm - 0
2022-12-15 21:17:03,769 [DEBUG] Changing year: 2010
2022-12-15 21:17:03,770 [DEBUG] Changing model: tcn - 0
2022-12-15 21:17:03,773 [DEBUG] Changing year: 2010
2022-12-15 21:17:03,773 [DEBUG] Changing model: rnn - 0
2022-12-15 21:17:03,779 [DEBUG] Changing year: 2010
2022-12-15 21:17:03,780 [DEBUG] Changing model: gru - 0
2022-12-15 21:17:03,806 [DEBUG] Changing year: 2010
2022-12-15 21:17:03,808 [DEBUG] Changing model: transformer - 0
2022-12-15 21:17:21,908 [DEBUG] Changing year: 2011
2022-12-15 21:17:21,939 [DEBUG] Changing year: 2011
2022-12-15 21:17:21,943 [DEBUG] Changing year: 2011
2022-12-15 21:17:21,949 [DEBUG] Changing year: 2011
2022-12-15 21:17:21,977 [DEBUG] Changing year: 2011
2022-12-15 21:17:40,483 [DEBUG] Changing year: 2012
2022-12-15 21:17:40,483 [DEBUG] Changing model: lstm - 1
2022-12-15 21:17:40,510 [DEBUG] Changing year: 2012
2022-12-15 21:17:40,512 [DEBUG] Changing model: tcn - 1
2022-12-15 21:17:40,515 [DEBUG] Changing year: 2012
2022-12-15 21:17:40,515 [DEBUG] Changing model: rnn - 1
2022-12-15 21:17:40,521 [DEBUG] Changing year: 2012
2022-12-15 21:17:40,521 [DEBUG] Changing model: gru - 1
2022-12-15 21:17:40,548 [DEBUG] Changing year: 2012
2022-12-15 21:17:40,550 [DEBUG] Changing model: transformer - 1
2022-12-15 21:17:58,947 [DEBUG] Changing year: 2013
2022-12-15 21:17:58,977 [DEBUG] Changing year: 2013
2022-12-15 21:17:58,981 [DEBUG] Changing year: 2013
2022-12-15 21:17:58,987 [DEBUG] Changing year: 2013
2022-12-15 21:17:59,014 [DEBUG] Changing year: 2013
2022-12-15 21:18:17,653 [DEBUG] Changing year: 2014
2022-12-15 21:18:17,654 [DEBUG] Changing model: lstm - 2
2022-12-15 21:18:17,682 [DEBUG] Changing year: 2014
2022-12-15 21:18:17,684 [DEBUG] Changing model: tcn - 2
2022-12-15 21:18:17,687 [DEBUG] Changing year: 2014
2022-12-15 21:18:17,687 [DEBUG] Changing model: rnn - 2
2022-12-15 21:18:17,693 [DEBUG] Changing year: 2014
2022-12-15 21:18:17,693 [DEBUG] Changing model: gru - 2
2022-12-15 21:18:17,721 [DEBUG] Changing year: 2014
2022-12-15 21:18:17,723 [DEBUG] Changing model: transformer - 2
2022-12-15 21:18:36,502 [DEBUG] Changing year: 2015
2022-12-15 21:18:36,534 [DEBUG] Changing year: 2015
2022-12-15 21:18:36,539 [DEBUG] Changing year: 2015
2022-12-15 21:18:36,544 [DEBUG] Changing year: 2015
2022-12-15 21:18:36,571 [DEBUG] Changing year: 2015
2022-12-15 21:18:55,338 [DEBUG] Changing year: 2016
2022-12-15 21:18:55,338 [DEBUG] Changing model: lstm - 3
2022-12-15 21:18:55,368 [DEBUG] Changing year: 2016
2022-12-15 21:18:55,370 [DEBUG] Changing model: tcn - 3
2022-12-15 21:18:55,374 [DEBUG] Changing year: 2016
2022-12-15 21:18:55,374 [DEBUG] Changing model: rnn - 3
2022-12-15 21:18:55,381 [DEBUG] Changing year: 2016
2022-12-15 21:18:55,381 [DEBUG] Changing model: gru - 3
2022-12-15 21:18:55,409 [DEBUG] Changing year: 2016
2022-12-15 21:18:55,411 [DEBUG] Changing model: transformer - 3
2022-12-15 21:19:14,333 [DEBUG] Changing year: 2017
2022-12-15 21:19:14,364 [DEBUG] Changing year: 2017
2022-12-15 21:19:14,370 [DEBUG] Changing year: 2017
2022-12-15 21:19:14,375 [DEBUG] Changing year: 2017
2022-12-15 21:19:14,404 [DEBUG] Changing year: 2017
2022-12-15 21:19:33,316 [DEBUG] Changing year: 2018
2022-12-15 21:19:33,317 [DEBUG] Changing model: lstm - 4
2022-12-15 21:19:33,347 [DEBUG] Changing year: 2018
2022-12-15 21:19:33,349 [DEBUG] Changing model: tcn - 4
2022-12-15 21:19:33,352 [DEBUG] Changing year: 2018
2022-12-15 21:19:33,352 [DEBUG] Changing model: rnn - 4
2022-12-15 21:19:33,359 [DEBUG] Changing year: 2018
2022-12-15 21:19:33,359 [DEBUG] Changing model: gru - 4
2022-12-15 21:19:33,394 [DEBUG] Changing year: 2018
2022-12-15 21:19:33,396 [DEBUG] Changing model: transformer - 4
2022-12-15 21:19:52,374 [DEBUG] Changing year: 2019
2022-12-15 21:19:52,402 [DEBUG] Changing year: 2019
2022-12-15 21:19:52,408 [DEBUG] Changing year: 2019
2022-12-15 21:19:52,414 [DEBUG] Changing year: 2019
2022-12-15 21:19:52,442 [DEBUG] Changing year: 2019
2022-12-15 21:20:11,468 [DEBUG] Changing year: 2020
2022-12-15 21:20:11,469 [DEBUG] Changing model: lstm - 5
2022-12-15 21:20:11,498 [DEBUG] Changing year: 2020
2022-12-15 21:20:11,500 [DEBUG] Changing model: tcn - 5
2022-12-15 21:20:11,503 [DEBUG] Changing year: 2020
2022-12-15 21:20:11,503 [DEBUG] Changing model: rnn - 5
2022-12-15 21:20:11,509 [DEBUG] Changing year: 2020
2022-12-15 21:20:11,509 [DEBUG] Changing model: gru - 5
2022-12-15 21:20:11,537 [DEBUG] Changing year: 2020
2022-12-15 21:20:11,539 [DEBUG] Changing model: transformer - 5
2022-12-15 21:20:30,655 [DEBUG] Changing year: 2021
2022-12-15 21:20:30,684 [DEBUG] Changing year: 2021
2022-12-15 21:20:30,690 [DEBUG] Changing year: 2021
2022-12-15 21:20:30,695 [DEBUG] Changing year: 2021
2022-12-15 21:20:30,724 [DEBUG] Changing year: 2021
2022-12-15 21:20:49,909 [DEBUG] Changing year: 2022
2022-12-15 21:20:49,909 [DEBUG] Changing model: lstm - 6
2022-12-15 21:20:49,940 [DEBUG] Changing year: 2022
2022-12-15 21:20:49,943 [DEBUG] Changing model: tcn - 6
2022-12-15 21:20:49,946 [DEBUG] Changing year: 2022
2022-12-15 21:20:49,946 [DEBUG] Changing model: rnn - 6
2022-12-15 21:20:49,952 [DEBUG] Changing year: 2022
2022-12-15 21:20:49,953 [DEBUG] Changing model: gru - 6
2022-12-15 21:20:49,983 [DEBUG] Changing year: 2022
2022-12-15 21:20:49,985 [DEBUG] Changing model: transformer - 6
2022-12-15 21:21:04,150 [DEBUG] Backtesting results
2022-12-15 21:21:04,151 [DEBUG] ---------------------------------
2022-12-15 21:21:04,151 [DEBUG] Results of strategy: random
2022-12-15 21:21:04,152 [DEBUG] Expected returns: 24.42430293995839%
2022-12-15 21:21:04,152 [DEBUG] Volatilty: 38.918841866229606%
2022-12-15 21:21:04,152 [DEBUG] Sharpe Ratio: 0.627570137464745
2022-12-15 21:21:04,153 [DEBUG] MDD: -1.4592559177826259
2022-12-15 21:21:04,153 [DEBUG] ---------------------------------
2022-12-15 21:21:04,153 [DEBUG] Results of strategy: equal strategy
2022-12-15 21:21:04,155 [DEBUG] Expected returns: 19.099810829319914%
2022-12-15 21:21:04,155 [DEBUG] Volatilty: 27.671778722561047%
2022-12-15 21:21:04,155 [DEBUG] Sharpe Ratio: 0.6902270728895237
2022-12-15 21:21:04,156 [DEBUG] MDD: -1.2121061373370512
2022-12-15 21:21:04,156 [DEBUG] ---------------------------------
2022-12-15 21:21:04,156 [DEBUG] Results of strategy: lstm
2022-12-15 21:21:04,157 [DEBUG] Expected returns: 14.50090386287185%
2022-12-15 21:21:04,157 [DEBUG] Volatilty: 20.37516663810386%
2022-12-15 21:21:04,158 [DEBUG] Sharpe Ratio: 0.7116949824475803
2022-12-15 21:21:04,158 [DEBUG] MDD: -1.251342062257237
2022-12-15 21:21:04,158 [DEBUG] ---------------------------------
2022-12-15 21:21:04,159 [DEBUG] Results of strategy: tcn
2022-12-15 21:21:04,160 [DEBUG] Expected returns: 18.250581836458075%
2022-12-15 21:21:04,160 [DEBUG] Volatilty: 17.853436382671443%
2022-12-15 21:21:04,160 [DEBUG] Sharpe Ratio: 1.0222447625921527
2022-12-15 21:21:04,161 [DEBUG] MDD: -1.2173389017833673
2022-12-15 21:21:04,161 [DEBUG] ---------------------------------
2022-12-15 21:21:04,161 [DEBUG] Results of strategy: rnn
2022-12-15 21:21:04,163 [DEBUG] Expected returns: 8.786685076463217%
2022-12-15 21:21:04,163 [DEBUG] Volatilty: 7.734446485614072%
2022-12-15 21:21:04,163 [DEBUG] Sharpe Ratio: 1.1360457523115959
2022-12-15 21:21:04,164 [DEBUG] MDD: -1.7424281773486106
2022-12-15 21:21:04,164 [DEBUG] ---------------------------------
2022-12-15 21:21:04,164 [DEBUG] Results of strategy: gru
2022-12-15 21:21:04,166 [DEBUG] Expected returns: 8.775540523095557%
2022-12-15 21:21:04,166 [DEBUG] Volatilty: 7.739476961395872%
2022-12-15 21:21:04,166 [DEBUG] Sharpe Ratio: 1.1338673875337468
2022-12-15 21:21:04,166 [DEBUG] MDD: -1.7425743522290347
2022-12-15 21:21:04,167 [DEBUG] ---------------------------------
2022-12-15 21:21:04,167 [DEBUG] Results of strategy: transformer
2022-12-15 21:21:04,167 [DEBUG] Expected returns: 14.500903477537477%
2022-12-15 21:21:04,168 [DEBUG] Volatilty: 20.375166637093216%
2022-12-15 21:21:04,168 [DEBUG] Sharpe Ratio: 0.7116949635709199
2022-12-15 21:21:04,168 [DEBUG] MDD: -1.2513420579473127
2022-12-15 21:21:04,281 [DEBUG] Saving results
2022-12-15 21:21:04,556 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,556 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,556 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,556 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,556 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-15 21:21:04,559 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,559 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,559 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,559 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,559 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-15 21:21:04,603 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,603 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,603 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,603 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,603 [DEBUG] STREAM b'IDAT' 78 374
2022-12-15 21:21:04,604 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,604 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,604 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,605 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,605 [DEBUG] STREAM b'IDAT' 78 286
2022-12-15 21:21:04,606 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,606 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,606 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,606 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,606 [DEBUG] STREAM b'IDAT' 78 263
2022-12-15 21:21:04,607 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,608 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,608 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,608 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,608 [DEBUG] STREAM b'IDAT' 78 387
2022-12-15 21:21:04,609 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,609 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,609 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,609 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,609 [DEBUG] STREAM b'IDAT' 78 436
2022-12-15 21:21:04,610 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,610 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,610 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,610 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,610 [DEBUG] STREAM b'IDAT' 78 351
2022-12-15 21:21:04,612 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 21:21:04,612 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 21:21:04,612 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 21:21:04,612 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 21:21:04,612 [DEBUG] STREAM b'IDAT' 78 364
2022-12-15 21:21:05,256 [DEBUG] Saving models
