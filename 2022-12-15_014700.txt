2022-12-15 01:47:59,038 [DEBUG] use config:config-cuda-20-252.json
2022-12-15 01:47:59,039 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-15 01:47:59,039 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 2 year with 50 days

2022-12-15 01:47:59,039 [DEBUG] Getting data
2022-12-15 01:47:59,039 [DEBUG] Fetch data using the following parameters:
2022-12-15 01:47:59,039 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-15 01:47:59,039 [DEBUG] Start date: 2006-01-01
2022-12-15 01:47:59,039 [DEBUG] End date: 2022-10-01
2022-12-15 01:47:59,039 [DEBUG] Interval: 1d
2022-12-15 01:47:59,039 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-15 01:47:59,062 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-15 01:47:59,125 [DEBUG] Training and testing with the device: cuda
2022-12-15 01:47:59,125 [DEBUG] Training model: cuda-20-252
2022-12-15 01:48:00,624 [DEBUG] Training from 2006, 2007
2022-12-15 01:48:00,660 [DEBUG] [+] Creating LSTM model
2022-12-15 01:48:00,664 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:48:00,664 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0403, validation loss : 0.0664
[2/5] Train loss : 0.0601, validation loss : 0.0659
[3/5] Train loss : 0.0601, validation loss : 0.0659
[4/5] Train loss : 0.0601, validation loss : 0.0659
[5/5] Train loss : 0.0601, validation loss : 0.0659
2022-12-15 01:49:12,797 [DEBUG] [+] Creating TCN model
2022-12-15 01:49:12,802 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:49:12,803 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0528, validation loss : 0.0659
[2/5] Train loss : 0.0601, validation loss : 0.0659
[3/5] Train loss : 0.0601, validation loss : 0.0659
[4/5] Train loss : 0.0601, validation loss : 0.0659
[5/5] Train loss : 0.0601, validation loss : 0.0659
2022-12-15 01:49:23,722 [DEBUG] [+] Creating RNN model
2022-12-15 01:49:23,724 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:49:23,724 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1213, validation loss : 0.1079
[2/5] Train loss : 0.1238, validation loss : 0.1075
[3/5] Train loss : 0.1276, validation loss : 0.1567
[4/5] Train loss : 0.1376, validation loss : 0.1836
[5/5] Train loss : 0.1386, validation loss : 0.1890
2022-12-15 01:49:59,499 [DEBUG] [+] Creating GRU model
2022-12-15 01:49:59,503 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:49:59,503 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1147, validation loss : 0.1346
[2/5] Train loss : 0.1354, validation loss : 0.1689
[3/5] Train loss : 0.1372, validation loss : 0.1878
[4/5] Train loss : 0.1391, validation loss : 0.1904
[5/5] Train loss : 0.1401, validation loss : 0.1888
2022-12-15 01:53:06,591 [DEBUG] [+] Creating Transformer Encoder model
2022-12-15 01:53:06,595 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:53:06,595 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0541, validation loss : 0.0659
[2/5] Train loss : 0.0601, validation loss : 0.0659
[3/5] Train loss : 0.0601, validation loss : 0.0659
[4/5] Train loss : 0.0601, validation loss : 0.0659
[5/5] Train loss : 0.0601, validation loss : 0.0659
2022-12-15 01:53:24,081 [DEBUG] Training from 2008, 2009
2022-12-15 01:53:24,117 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:53:24,118 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0515, validation loss : 0.0983
[2/5] Train loss : -0.0515, validation loss : 0.0983
[3/5] Train loss : -0.0515, validation loss : 0.0983
[4/5] Train loss : -0.0515, validation loss : 0.0983
[5/5] Train loss : -0.0515, validation loss : 0.0983
2022-12-15 01:54:44,919 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:54:44,919 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0515, validation loss : 0.0983
[2/5] Train loss : -0.0515, validation loss : 0.0983
[3/5] Train loss : -0.0515, validation loss : 0.0983
[4/5] Train loss : -0.0515, validation loss : 0.0983
[5/5] Train loss : -0.0515, validation loss : 0.0983
2022-12-15 01:54:56,693 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:54:56,693 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0059, validation loss : -0.0082
[2/5] Train loss : -0.0121, validation loss : -0.0090
[3/5] Train loss : 0.0111, validation loss : -0.0086
[4/5] Train loss : -0.0118, validation loss : -0.0086
[5/5] Train loss : -0.0129, validation loss : -0.0086
2022-12-15 01:55:38,045 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:55:38,046 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0215, validation loss : 0.1368
[2/5] Train loss : -0.0189, validation loss : 0.1354
[3/5] Train loss : -0.0186, validation loss : 0.1349
[4/5] Train loss : -0.0185, validation loss : 0.1347
[5/5] Train loss : -0.0229, validation loss : 0.1349
2022-12-15 01:59:14,361 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:59:14,362 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0515, validation loss : 0.0983
[2/5] Train loss : -0.0515, validation loss : 0.0983
[3/5] Train loss : -0.0509, validation loss : 0.0984
[4/5] Train loss : -0.0537, validation loss : 0.0688
[5/5] Train loss : -0.0253, validation loss : 0.0694
2022-12-15 01:59:26,923 [DEBUG] Training from 2010, 2011
2022-12-15 01:59:26,944 [DEBUG] [+] Setting sgd optimizer
2022-12-15 01:59:26,944 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0423, validation loss : -0.0350
[2/5] Train loss : 0.0423, validation loss : -0.0350
[3/5] Train loss : 0.0423, validation loss : -0.0350
[4/5] Train loss : 0.0423, validation loss : -0.0350
[5/5] Train loss : 0.0423, validation loss : -0.0350
2022-12-15 02:00:32,497 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:00:32,497 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0423, validation loss : -0.0350
[2/5] Train loss : 0.0423, validation loss : -0.0350
[3/5] Train loss : 0.0423, validation loss : -0.0350
[4/5] Train loss : 0.0423, validation loss : -0.0350
[5/5] Train loss : 0.0423, validation loss : -0.0350
2022-12-15 02:00:41,483 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:00:41,483 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0531, validation loss : 0.0230
[2/5] Train loss : 0.1012, validation loss : 0.0212
[3/5] Train loss : 0.1187, validation loss : 0.0204
[4/5] Train loss : 0.1201, validation loss : 0.0175
[5/5] Train loss : 0.1214, validation loss : 0.0188
2022-12-15 02:01:14,286 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:01:14,287 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1048, validation loss : 0.0206
[2/5] Train loss : 0.1267, validation loss : 0.0195
[3/5] Train loss : 0.1268, validation loss : 0.0197
[4/5] Train loss : 0.1270, validation loss : 0.0199
[5/5] Train loss : 0.1270, validation loss : 0.0200
2022-12-15 02:04:07,200 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:04:07,201 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0283, validation loss : -0.0858
[2/5] Train loss : 0.0283, validation loss : -0.0858
[3/5] Train loss : 0.0282, validation loss : -0.0858
[4/5] Train loss : 0.0283, validation loss : -0.0858
[5/5] Train loss : 0.0283, validation loss : -0.0857
2022-12-15 02:04:19,272 [DEBUG] Training from 2012, 2013
2022-12-15 02:04:19,292 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:04:19,293 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0153, validation loss : 0.0429
[2/5] Train loss : 0.0153, validation loss : 0.0429
[3/5] Train loss : 0.0153, validation loss : 0.0429
[4/5] Train loss : 0.0153, validation loss : 0.0429
[5/5] Train loss : 0.0153, validation loss : 0.0429
2022-12-15 02:05:25,615 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:05:25,615 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0153, validation loss : 0.0429
[2/5] Train loss : 0.0153, validation loss : 0.0429
[3/5] Train loss : 0.0153, validation loss : 0.0429
[4/5] Train loss : 0.0153, validation loss : 0.0429
[5/5] Train loss : 0.0153, validation loss : 0.0429
2022-12-15 02:05:34,677 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:05:34,678 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0815, validation loss : 0.0988
[2/5] Train loss : 0.0856, validation loss : 0.0954
[3/5] Train loss : 0.1034, validation loss : 0.1007
[4/5] Train loss : 0.1097, validation loss : 0.1019
[5/5] Train loss : 0.1128, validation loss : 0.1023
2022-12-15 02:06:07,594 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:06:07,595 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1111, validation loss : 0.1057
[2/5] Train loss : 0.1113, validation loss : 0.1069
[3/5] Train loss : 0.1132, validation loss : 0.1077
[4/5] Train loss : 0.1139, validation loss : 0.1094
[5/5] Train loss : 0.1141, validation loss : 0.1129
2022-12-15 02:09:02,689 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:09:02,690 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0210, validation loss : -0.0176
[2/5] Train loss : -0.0210, validation loss : -0.0176
[3/5] Train loss : -0.0210, validation loss : -0.0176
[4/5] Train loss : -0.0210, validation loss : -0.0176
[5/5] Train loss : -0.0210, validation loss : -0.0176
2022-12-15 02:09:16,900 [DEBUG] Training from 2014, 2015
2022-12-15 02:09:16,921 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:09:16,921 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0090, validation loss : -0.0582
[2/5] Train loss : 0.0090, validation loss : -0.0582
[3/5] Train loss : 0.0090, validation loss : -0.0582
[4/5] Train loss : 0.0090, validation loss : -0.0582
[5/5] Train loss : 0.0090, validation loss : -0.0582
2022-12-15 02:10:39,273 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:10:39,274 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0090, validation loss : -0.0582
[2/5] Train loss : 0.0090, validation loss : -0.0582
[3/5] Train loss : 0.0090, validation loss : -0.0582
[4/5] Train loss : 0.0090, validation loss : -0.0582
[5/5] Train loss : 0.0090, validation loss : -0.0582
2022-12-15 02:10:50,589 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:10:50,590 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0798, validation loss : -0.0411
[2/5] Train loss : 0.0423, validation loss : -0.0418
[3/5] Train loss : 0.0442, validation loss : -0.0421
[4/5] Train loss : 0.0446, validation loss : -0.0428
[5/5] Train loss : 0.0445, validation loss : -0.0432
2022-12-15 02:11:33,131 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:11:33,131 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0781, validation loss : -0.0431
[2/5] Train loss : 0.0463, validation loss : -0.0442
[3/5] Train loss : 0.0470, validation loss : -0.0450
[4/5] Train loss : 0.0473, validation loss : -0.0460
[5/5] Train loss : 0.0477, validation loss : -0.0469
2022-12-15 02:14:25,789 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:14:25,790 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0337, validation loss : -0.0964
[2/5] Train loss : -0.0337, validation loss : -0.0964
[3/5] Train loss : -0.0337, validation loss : -0.0964
[4/5] Train loss : -0.0337, validation loss : -0.0964
[5/5] Train loss : -0.0015, validation loss : -0.0582
2022-12-15 02:14:37,503 [DEBUG] Training from 2016, 2017
2022-12-15 02:14:37,524 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:14:37,525 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0106, validation loss : 0.0688
[2/5] Train loss : 0.0106, validation loss : 0.0688
[3/5] Train loss : 0.0106, validation loss : 0.0688
[4/5] Train loss : 0.0106, validation loss : 0.0688
[5/5] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 02:15:44,026 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:15:44,026 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0106, validation loss : 0.0688
[2/5] Train loss : 0.0106, validation loss : 0.0688
[3/5] Train loss : 0.0106, validation loss : 0.0688
[4/5] Train loss : 0.0106, validation loss : 0.0688
[5/5] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 02:15:53,278 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:15:53,278 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0494, validation loss : 0.3388
[2/5] Train loss : 0.0820, validation loss : 0.3452
[3/5] Train loss : 0.0842, validation loss : 0.3482
[4/5] Train loss : 0.0852, validation loss : 0.3506
[5/5] Train loss : 0.0862, validation loss : 0.3527
2022-12-15 02:16:27,238 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:16:27,239 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0602, validation loss : 0.3441
[2/5] Train loss : 0.0852, validation loss : 0.3491
[3/5] Train loss : 0.0864, validation loss : 0.3515
[4/5] Train loss : 0.0873, validation loss : 0.3533
[5/5] Train loss : 0.0880, validation loss : 0.3547
2022-12-15 02:19:22,913 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:19:22,913 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0107, validation loss : 0.0688
[2/5] Train loss : 0.0106, validation loss : 0.0688
[3/5] Train loss : 0.0106, validation loss : 0.0688
[4/5] Train loss : 0.0106, validation loss : 0.0688
[5/5] Train loss : 0.0106, validation loss : 0.0688
2022-12-15 02:19:36,085 [DEBUG] Training from 2018, 2019
2022-12-15 02:19:36,109 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:19:36,110 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0201, validation loss : -0.0108
[2/5] Train loss : 0.0201, validation loss : -0.0108
[3/5] Train loss : 0.0201, validation loss : -0.0108
[4/5] Train loss : 0.0201, validation loss : -0.0108
[5/5] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 02:20:42,934 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:20:42,935 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0201, validation loss : -0.0108
[2/5] Train loss : 0.0201, validation loss : -0.0108
[3/5] Train loss : 0.0201, validation loss : -0.0108
[4/5] Train loss : 0.0201, validation loss : -0.0108
[5/5] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 02:20:55,979 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:20:55,980 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0621, validation loss : -0.0233
[2/5] Train loss : 0.0440, validation loss : -0.0225
[3/5] Train loss : 0.0442, validation loss : -0.0185
[4/5] Train loss : 0.0489, validation loss : -0.0104
[5/5] Train loss : 0.0527, validation loss : -0.0057
2022-12-15 02:21:38,065 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:21:38,066 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0676, validation loss : -0.0005
[2/5] Train loss : 0.0524, validation loss : 0.0007
[3/5] Train loss : 0.0505, validation loss : 0.0042
[4/5] Train loss : 0.0494, validation loss : 0.0086
[5/5] Train loss : 0.0478, validation loss : 0.0152
2022-12-15 02:25:01,759 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:25:01,760 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0201, validation loss : -0.0108
[2/5] Train loss : 0.0201, validation loss : -0.0107
[3/5] Train loss : 0.0201, validation loss : -0.0107
[4/5] Train loss : 0.0201, validation loss : -0.0108
[5/5] Train loss : 0.0201, validation loss : -0.0108
2022-12-15 02:25:18,956 [DEBUG] Training from 2020, 2021
2022-12-15 02:25:18,984 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:25:18,985 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0758, validation loss : 0.0579
[2/5] Train loss : 0.0758, validation loss : 0.0579
[3/5] Train loss : 0.0758, validation loss : 0.0579
[4/5] Train loss : 0.0758, validation loss : 0.0579
[5/5] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 02:26:39,858 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:26:39,858 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0758, validation loss : 0.0579
[2/5] Train loss : 0.0758, validation loss : 0.0579
[3/5] Train loss : 0.0758, validation loss : 0.0579
[4/5] Train loss : 0.0758, validation loss : 0.0579
[5/5] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 02:26:51,459 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:26:51,460 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1724, validation loss : 0.1656
[2/5] Train loss : 0.0605, validation loss : 0.0250
[3/5] Train loss : 0.1497, validation loss : 0.1684
[4/5] Train loss : 0.1845, validation loss : 0.1695
[5/5] Train loss : 0.1828, validation loss : 0.1697
2022-12-15 02:27:39,067 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:27:39,068 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1905, validation loss : 0.1694
[2/5] Train loss : 0.1782, validation loss : 0.1688
[3/5] Train loss : 0.1970, validation loss : 0.1683
[4/5] Train loss : 0.2042, validation loss : 0.1681
[5/5] Train loss : 0.2054, validation loss : 0.1678
2022-12-15 02:31:40,374 [DEBUG] [+] Setting sgd optimizer
2022-12-15 02:31:40,374 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0757, validation loss : 0.0579
[2/5] Train loss : 0.0758, validation loss : 0.0579
[3/5] Train loss : 0.0758, validation loss : 0.0579
[4/5] Train loss : 0.0758, validation loss : 0.0579
[5/5] Train loss : 0.0758, validation loss : 0.0579
2022-12-15 02:31:58,984 [DEBUG] Backtesting strategies
2022-12-15 02:31:58,997 [DEBUG] First year: 2008
2022-12-15 02:31:59,021 [DEBUG] First year: 2008
2022-12-15 02:31:59,025 [DEBUG] First year: 2008
2022-12-15 02:31:59,034 [DEBUG] First year: 2008
2022-12-15 02:31:59,080 [DEBUG] First year: 2008
2022-12-15 02:32:16,658 [DEBUG] Changing year: 2009
2022-12-15 02:32:16,676 [DEBUG] Changing year: 2009
2022-12-15 02:32:16,683 [DEBUG] Changing year: 2009
2022-12-15 02:32:16,691 [DEBUG] Changing year: 2009
2022-12-15 02:32:16,734 [DEBUG] Changing year: 2009
2022-12-15 02:32:38,759 [DEBUG] Changing year: 2010
2022-12-15 02:32:38,760 [DEBUG] Changing model: lstm - 0
2022-12-15 02:32:38,779 [DEBUG] Changing year: 2010
2022-12-15 02:32:38,780 [DEBUG] Changing model: tcn - 0
2022-12-15 02:32:38,785 [DEBUG] Changing year: 2010
2022-12-15 02:32:38,785 [DEBUG] Changing model: rnn - 0
2022-12-15 02:32:38,794 [DEBUG] Changing year: 2010
2022-12-15 02:32:38,795 [DEBUG] Changing model: gru - 0
2022-12-15 02:32:38,841 [DEBUG] Changing year: 2010
2022-12-15 02:32:38,843 [DEBUG] Changing model: transformer - 0
2022-12-15 02:33:01,702 [DEBUG] Changing year: 2011
2022-12-15 02:33:01,720 [DEBUG] Changing year: 2011
2022-12-15 02:33:01,723 [DEBUG] Changing year: 2011
2022-12-15 02:33:01,734 [DEBUG] Changing year: 2011
2022-12-15 02:33:01,782 [DEBUG] Changing year: 2011
2022-12-15 02:33:24,659 [DEBUG] Changing year: 2012
2022-12-15 02:33:24,659 [DEBUG] Changing model: lstm - 1
2022-12-15 02:33:24,677 [DEBUG] Changing year: 2012
2022-12-15 02:33:24,678 [DEBUG] Changing model: tcn - 1
2022-12-15 02:33:24,681 [DEBUG] Changing year: 2012
2022-12-15 02:33:24,681 [DEBUG] Changing model: rnn - 1
2022-12-15 02:33:24,695 [DEBUG] Changing year: 2012
2022-12-15 02:33:24,696 [DEBUG] Changing model: gru - 1
2022-12-15 02:33:24,745 [DEBUG] Changing year: 2012
2022-12-15 02:33:24,747 [DEBUG] Changing model: transformer - 1
2022-12-15 02:33:47,089 [DEBUG] Changing year: 2013
2022-12-15 02:33:47,108 [DEBUG] Changing year: 2013
2022-12-15 02:33:47,113 [DEBUG] Changing year: 2013
2022-12-15 02:33:47,121 [DEBUG] Changing year: 2013
2022-12-15 02:33:47,161 [DEBUG] Changing year: 2013
2022-12-15 02:34:09,660 [DEBUG] Changing year: 2014
2022-12-15 02:34:09,661 [DEBUG] Changing model: lstm - 2
2022-12-15 02:34:09,679 [DEBUG] Changing year: 2014
2022-12-15 02:34:09,680 [DEBUG] Changing model: tcn - 2
2022-12-15 02:34:09,684 [DEBUG] Changing year: 2014
2022-12-15 02:34:09,685 [DEBUG] Changing model: rnn - 2
2022-12-15 02:34:09,698 [DEBUG] Changing year: 2014
2022-12-15 02:34:09,699 [DEBUG] Changing model: gru - 2
2022-12-15 02:34:09,754 [DEBUG] Changing year: 2014
2022-12-15 02:34:09,757 [DEBUG] Changing model: transformer - 2
2022-12-15 02:34:33,342 [DEBUG] Changing year: 2015
2022-12-15 02:34:33,363 [DEBUG] Changing year: 2015
2022-12-15 02:34:33,368 [DEBUG] Changing year: 2015
2022-12-15 02:34:33,384 [DEBUG] Changing year: 2015
2022-12-15 02:34:33,430 [DEBUG] Changing year: 2015
2022-12-15 02:34:55,638 [DEBUG] Changing year: 2016
2022-12-15 02:34:55,639 [DEBUG] Changing model: lstm - 3
2022-12-15 02:34:55,651 [DEBUG] Changing year: 2016
2022-12-15 02:34:55,652 [DEBUG] Changing model: tcn - 3
2022-12-15 02:34:55,657 [DEBUG] Changing year: 2016
2022-12-15 02:34:55,657 [DEBUG] Changing model: rnn - 3
2022-12-15 02:34:55,667 [DEBUG] Changing year: 2016
2022-12-15 02:34:55,669 [DEBUG] Changing model: gru - 3
2022-12-15 02:34:55,711 [DEBUG] Changing year: 2016
2022-12-15 02:34:55,713 [DEBUG] Changing model: transformer - 3
2022-12-15 02:35:18,841 [DEBUG] Changing year: 2017
2022-12-15 02:35:18,857 [DEBUG] Changing year: 2017
2022-12-15 02:35:18,865 [DEBUG] Changing year: 2017
2022-12-15 02:35:18,873 [DEBUG] Changing year: 2017
2022-12-15 02:35:18,917 [DEBUG] Changing year: 2017
2022-12-15 02:35:42,034 [DEBUG] Changing year: 2018
2022-12-15 02:35:42,034 [DEBUG] Changing model: lstm - 4
2022-12-15 02:35:42,047 [DEBUG] Changing year: 2018
2022-12-15 02:35:42,049 [DEBUG] Changing model: tcn - 4
2022-12-15 02:35:42,052 [DEBUG] Changing year: 2018
2022-12-15 02:35:42,053 [DEBUG] Changing model: rnn - 4
2022-12-15 02:35:42,063 [DEBUG] Changing year: 2018
2022-12-15 02:35:42,063 [DEBUG] Changing model: gru - 4
2022-12-15 02:35:42,107 [DEBUG] Changing year: 2018
2022-12-15 02:35:42,109 [DEBUG] Changing model: transformer - 4
2022-12-15 02:36:04,460 [DEBUG] Changing year: 2019
2022-12-15 02:36:04,481 [DEBUG] Changing year: 2019
2022-12-15 02:36:04,485 [DEBUG] Changing year: 2019
2022-12-15 02:36:04,494 [DEBUG] Changing year: 2019
2022-12-15 02:36:04,536 [DEBUG] Changing year: 2019
2022-12-15 02:36:26,642 [DEBUG] Changing year: 2020
2022-12-15 02:36:26,642 [DEBUG] Changing model: lstm - 5
2022-12-15 02:36:26,657 [DEBUG] Changing year: 2020
2022-12-15 02:36:26,658 [DEBUG] Changing model: tcn - 5
2022-12-15 02:36:26,662 [DEBUG] Changing year: 2020
2022-12-15 02:36:26,662 [DEBUG] Changing model: rnn - 5
2022-12-15 02:36:26,672 [DEBUG] Changing year: 2020
2022-12-15 02:36:26,673 [DEBUG] Changing model: gru - 5
2022-12-15 02:36:26,713 [DEBUG] Changing year: 2020
2022-12-15 02:36:26,715 [DEBUG] Changing model: transformer - 5
2022-12-15 02:36:50,208 [DEBUG] Changing year: 2021
2022-12-15 02:36:50,228 [DEBUG] Changing year: 2021
2022-12-15 02:36:50,232 [DEBUG] Changing year: 2021
2022-12-15 02:36:50,238 [DEBUG] Changing year: 2021
2022-12-15 02:36:50,294 [DEBUG] Changing year: 2021
2022-12-15 02:37:13,325 [DEBUG] Changing year: 2022
2022-12-15 02:37:13,325 [DEBUG] Changing model: lstm - 6
2022-12-15 02:37:13,341 [DEBUG] Changing year: 2022
2022-12-15 02:37:13,342 [DEBUG] Changing model: tcn - 6
2022-12-15 02:37:13,346 [DEBUG] Changing year: 2022
2022-12-15 02:37:13,347 [DEBUG] Changing model: rnn - 6
2022-12-15 02:37:13,354 [DEBUG] Changing year: 2022
2022-12-15 02:37:13,355 [DEBUG] Changing model: gru - 6
2022-12-15 02:37:13,397 [DEBUG] Changing year: 2022
2022-12-15 02:37:13,400 [DEBUG] Changing model: transformer - 6
2022-12-15 02:37:30,396 [DEBUG] Backtesting results
2022-12-15 02:37:30,396 [DEBUG] ---------------------------------
2022-12-15 02:37:30,396 [DEBUG] Results of strategy: random
2022-12-15 02:37:30,398 [DEBUG] Expected returns: 2.066722187199614%
2022-12-15 02:37:30,398 [DEBUG] Volatilty: 39.292033330876215%
2022-12-15 02:37:30,398 [DEBUG] Sharpe Ratio: 0.05259901338767203
2022-12-15 02:37:30,399 [DEBUG] MDD: -1.2493970205773681
2022-12-15 02:37:30,399 [DEBUG] ---------------------------------
2022-12-15 02:37:30,399 [DEBUG] Results of strategy: equal strategy
2022-12-15 02:37:30,400 [DEBUG] Expected returns: 19.099810829319914%
2022-12-15 02:37:30,400 [DEBUG] Volatilty: 27.671778722561047%
2022-12-15 02:37:30,400 [DEBUG] Sharpe Ratio: 0.6902270728895237
2022-12-15 02:37:30,401 [DEBUG] MDD: -1.2121061373370512
2022-12-15 02:37:30,401 [DEBUG] ---------------------------------
2022-12-15 02:37:30,401 [DEBUG] Results of strategy: lstm
2022-12-15 02:37:30,402 [DEBUG] Expected returns: 17.8354235981655%
2022-12-15 02:37:30,403 [DEBUG] Volatilty: 15.711628284848942%
2022-12-15 02:37:30,403 [DEBUG] Sharpe Ratio: 1.1351734699174738
2022-12-15 02:37:30,403 [DEBUG] MDD: -1.2536962838422436
2022-12-15 02:37:30,403 [DEBUG] ---------------------------------
2022-12-15 02:37:30,403 [DEBUG] Results of strategy: tcn
2022-12-15 02:37:30,404 [DEBUG] Expected returns: 17.835423008925165%
2022-12-15 02:37:30,404 [DEBUG] Volatilty: 15.711628306900607%
2022-12-15 02:37:30,404 [DEBUG] Sharpe Ratio: 1.135173430820775
2022-12-15 02:37:30,405 [DEBUG] MDD: -1.2536962604713813
2022-12-15 02:37:30,405 [DEBUG] ---------------------------------
2022-12-15 02:37:30,405 [DEBUG] Results of strategy: rnn
2022-12-15 02:37:30,406 [DEBUG] Expected returns: 7.945244903000857%
2022-12-15 02:37:30,406 [DEBUG] Volatilty: 7.991879828128651%
2022-12-15 02:37:30,406 [DEBUG] Sharpe Ratio: 0.9941647114157479
2022-12-15 02:37:30,406 [DEBUG] MDD: -1.7284477586601736
2022-12-15 02:37:30,406 [DEBUG] ---------------------------------
2022-12-15 02:37:30,406 [DEBUG] Results of strategy: gru
2022-12-15 02:37:30,407 [DEBUG] Expected returns: 7.822368860851767%
2022-12-15 02:37:30,407 [DEBUG] Volatilty: 8.065632764024594%
2022-12-15 02:37:30,407 [DEBUG] Sharpe Ratio: 0.9698394521186403
2022-12-15 02:37:30,408 [DEBUG] MDD: -1.7337906084846177
2022-12-15 02:37:30,408 [DEBUG] ---------------------------------
2022-12-15 02:37:30,408 [DEBUG] Results of strategy: transformer
2022-12-15 02:37:30,409 [DEBUG] Expected returns: 17.83611380294346%
2022-12-15 02:37:30,409 [DEBUG] Volatilty: 15.711570882766205%
2022-12-15 02:37:30,409 [DEBUG] Sharpe Ratio: 1.1352215469751425
2022-12-15 02:37:30,410 [DEBUG] MDD: -1.2536963259753937
2022-12-15 02:37:30,574 [DEBUG] Saving results
2022-12-15 02:37:30,974 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:30,974 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:30,974 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:30,975 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:30,975 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-15 02:37:30,979 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:30,979 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:30,979 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:30,979 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:30,979 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-15 02:37:31,042 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,042 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,042 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,042 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,042 [DEBUG] STREAM b'IDAT' 78 374
2022-12-15 02:37:31,044 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,045 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,045 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,045 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,045 [DEBUG] STREAM b'IDAT' 78 286
2022-12-15 02:37:31,050 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,050 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,051 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,051 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,051 [DEBUG] STREAM b'IDAT' 78 263
2022-12-15 02:37:31,053 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,053 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,053 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,053 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,053 [DEBUG] STREAM b'IDAT' 78 387
2022-12-15 02:37:31,054 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,054 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,055 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,055 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,055 [DEBUG] STREAM b'IDAT' 78 436
2022-12-15 02:37:31,056 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,056 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,056 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,056 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,056 [DEBUG] STREAM b'IDAT' 78 351
2022-12-15 02:37:31,058 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 02:37:31,058 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 02:37:31,058 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 02:37:31,058 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 02:37:31,058 [DEBUG] STREAM b'IDAT' 78 364
2022-12-15 02:37:32,049 [DEBUG] Saving models
