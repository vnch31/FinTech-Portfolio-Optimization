2022-12-15 03:35:19,802 [DEBUG] use config:config-cuda-20-252.json
2022-12-15 03:35:19,803 [DEBUG] Creating, training and testing models with the following parameters:
2022-12-15 03:35:19,803 [DEBUG] VTI AGG DBC ^VIX
from 2006-01-01 to 2022-10-01 with 1d interval
retrain every 2 year with 50 days

2022-12-15 03:35:19,803 [DEBUG] Getting data
2022-12-15 03:35:19,803 [DEBUG] Fetch data using the following parameters:
2022-12-15 03:35:19,803 [DEBUG] Tickers: VTI AGG DBC ^VIX
2022-12-15 03:35:19,803 [DEBUG] Start date: 2006-01-01
2022-12-15 03:35:19,803 [DEBUG] End date: 2022-10-01
2022-12-15 03:35:19,803 [DEBUG] Interval: 1d
2022-12-15 03:35:19,803 [DEBUG] File dataset_2006-01-01_2022-10-01_VTI_AGG_DBC_^VIX.csv, no need to download, loading file...
2022-12-15 03:35:19,832 [DEBUG]        Unnamed: 0        Date Ticker  ...         Low        Open      Volume
0               0  2006-01-03    AGG  ...   59.801179   59.866725    170600.0
1               1  2006-01-03    VTI  ...   44.781733   45.091552   1769800.0
2               2  2006-01-03   ^VIX  ...   10.990000   12.250000         0.0
3               3  2006-01-04    AGG  ...   59.950149   59.997819    284500.0
4               4  2006-01-04    VTI  ...   45.652858   45.678373    763600.0
...           ...         ...    ...  ...         ...         ...         ...
16836       16836  2022-09-29   ^VIX  ...   31.160000   31.670000         0.0
16837       16837  2022-09-30    AGG  ...   95.320501   95.984443  14376300.0
16838       16838  2022-09-30    DBC  ...   23.840000   24.020000   3947600.0
16839       16839  2022-09-30    VTI  ...  179.279999  181.559998   8431700.0
16840       16840  2022-09-30   ^VIX  ...   29.389999   31.610001         0.0

[16841 rows x 8 columns]
2022-12-15 03:35:19,895 [DEBUG] Training and testing with the device: cuda
2022-12-15 03:35:19,895 [DEBUG] Training model: cuda-20-252
2022-12-15 03:35:21,487 [DEBUG] Training from 2006, 2007
2022-12-15 03:35:21,521 [DEBUG] [+] Creating LSTM model
2022-12-15 03:35:21,530 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:35:21,530 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0390, validation loss : 0.0632
[2/5] Train loss : 0.0885, validation loss : 0.0793
[3/5] Train loss : 0.0933, validation loss : 0.0793
[4/5] Train loss : 0.0933, validation loss : 0.0793
[5/5] Train loss : 0.0933, validation loss : 0.0793
2022-12-15 03:38:25,314 [DEBUG] [+] Creating TCN model
2022-12-15 03:38:25,317 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:38:25,318 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0345, validation loss : 0.1622
[2/5] Train loss : 0.0384, validation loss : 0.1622
[3/5] Train loss : 0.0384, validation loss : 0.1622
[4/5] Train loss : 0.0384, validation loss : 0.1622
[5/5] Train loss : 0.0383, validation loss : 0.1622
2022-12-15 03:38:35,737 [DEBUG] [+] Creating RNN model
2022-12-15 03:38:35,739 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:38:35,739 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1375, validation loss : 0.0733
[2/5] Train loss : 0.1591, validation loss : 0.0781
[3/5] Train loss : 0.1630, validation loss : 0.0951
[4/5] Train loss : 0.1716, validation loss : 0.0972
[5/5] Train loss : 0.1743, validation loss : 0.1024
2022-12-15 03:39:13,945 [DEBUG] [+] Creating GRU model
2022-12-15 03:39:13,948 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:39:13,948 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1510, validation loss : 0.0726
[2/5] Train loss : 0.1650, validation loss : 0.0917
[3/5] Train loss : 0.1735, validation loss : 0.1002
[4/5] Train loss : 0.1789, validation loss : 0.0997
[5/5] Train loss : 0.1820, validation loss : 0.0983
2022-12-15 03:42:30,756 [DEBUG] [+] Creating Transformer Encoder model
2022-12-15 03:42:30,759 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:42:30,760 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0742, validation loss : 0.0793
[2/5] Train loss : 0.0931, validation loss : 0.0779
[3/5] Train loss : 0.0934, validation loss : 0.0793
[4/5] Train loss : 0.0932, validation loss : 0.0793
[5/5] Train loss : 0.0933, validation loss : 0.0793
2022-12-15 03:42:47,229 [DEBUG] Training from 2008, 2009
2022-12-15 03:42:47,253 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:42:47,254 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0589, validation loss : 0.1379
[2/5] Train loss : -0.0589, validation loss : 0.1379
[3/5] Train loss : -0.0589, validation loss : 0.1379
[4/5] Train loss : -0.0589, validation loss : 0.1379
[5/5] Train loss : -0.0589, validation loss : 0.1379
2022-12-15 03:46:32,741 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:46:32,742 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0191, validation loss : 0.0850
[2/5] Train loss : -0.0191, validation loss : 0.0850
[3/5] Train loss : -0.0191, validation loss : 0.0850
[4/5] Train loss : -0.0191, validation loss : 0.0850
[5/5] Train loss : -0.0191, validation loss : 0.0850
2022-12-15 03:46:45,660 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:46:45,660 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0221, validation loss : 0.1221
[2/5] Train loss : 0.0267, validation loss : 0.1218
[3/5] Train loss : 0.0268, validation loss : 0.1217
[4/5] Train loss : 0.0269, validation loss : 0.1217
[5/5] Train loss : 0.0269, validation loss : 0.1216
2022-12-15 03:47:33,918 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:47:33,918 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0585, validation loss : -0.0276
[2/5] Train loss : -0.0082, validation loss : -0.0282
[3/5] Train loss : -0.0064, validation loss : -0.0202
[4/5] Train loss : -0.0058, validation loss : -0.0208
[5/5] Train loss : -0.0052, validation loss : -0.0212
2022-12-15 03:51:24,451 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:51:24,452 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0589, validation loss : 0.1379
[2/5] Train loss : -0.0589, validation loss : 0.1379
[3/5] Train loss : -0.0586, validation loss : 0.1371
[4/5] Train loss : -0.0587, validation loss : 0.1369
[5/5] Train loss : -0.0592, validation loss : 0.1375
2022-12-15 03:51:40,508 [DEBUG] Training from 2010, 2011
2022-12-15 03:51:40,534 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:51:40,535 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0782, validation loss : -0.0072
[2/5] Train loss : 0.0782, validation loss : -0.0072
[3/5] Train loss : 0.0782, validation loss : -0.0072
[4/5] Train loss : 0.0782, validation loss : -0.0072
[5/5] Train loss : 0.0782, validation loss : -0.0072
2022-12-15 03:55:25,387 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:55:25,388 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0419, validation loss : -0.1044
[2/5] Train loss : 0.0419, validation loss : -0.1044
[3/5] Train loss : 0.0419, validation loss : -0.1044
[4/5] Train loss : 0.0419, validation loss : -0.1044
[5/5] Train loss : 0.0418, validation loss : -0.1044
2022-12-15 03:55:37,832 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:55:37,833 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0783, validation loss : -0.0446
[2/5] Train loss : 0.1009, validation loss : 0.0664
[3/5] Train loss : 0.1070, validation loss : 0.0629
[4/5] Train loss : 0.1269, validation loss : 0.0287
[5/5] Train loss : 0.1415, validation loss : 0.0404
2022-12-15 03:56:24,889 [DEBUG] [+] Setting sgd optimizer
2022-12-15 03:56:24,890 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0065, validation loss : -0.0468
[2/5] Train loss : 0.0899, validation loss : 0.0552
[3/5] Train loss : 0.1393, validation loss : 0.0535
[4/5] Train loss : 0.1461, validation loss : 0.0465
[5/5] Train loss : 0.1448, validation loss : 0.0425
2022-12-15 04:00:27,712 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:00:27,712 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0781, validation loss : -0.0072
[2/5] Train loss : 0.0782, validation loss : -0.0072
[3/5] Train loss : 0.0782, validation loss : -0.0072
[4/5] Train loss : 0.0781, validation loss : -0.0072
[5/5] Train loss : 0.0782, validation loss : -0.0072
2022-12-15 04:00:45,964 [DEBUG] Training from 2012, 2013
2022-12-15 04:00:45,992 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:00:45,993 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0454, validation loss : 0.0880
[2/5] Train loss : 0.0454, validation loss : 0.0880
[3/5] Train loss : 0.0454, validation loss : 0.0880
[4/5] Train loss : 0.0454, validation loss : 0.0880
[5/5] Train loss : 0.0454, validation loss : 0.0880
2022-12-15 04:04:45,216 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:04:45,216 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0254, validation loss : -0.0274
[2/5] Train loss : -0.0254, validation loss : -0.0274
[3/5] Train loss : -0.0254, validation loss : -0.0274
[4/5] Train loss : -0.0254, validation loss : -0.0274
[5/5] Train loss : -0.0254, validation loss : -0.0274
2022-12-15 04:04:58,703 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:04:58,704 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1762, validation loss : 0.0617
[2/5] Train loss : 0.1486, validation loss : 0.0661
[3/5] Train loss : 0.1456, validation loss : 0.1053
[4/5] Train loss : 0.1594, validation loss : 0.0821
[5/5] Train loss : 0.1601, validation loss : 0.1640
2022-12-15 04:05:46,872 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:05:46,872 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1594, validation loss : 0.1643
[2/5] Train loss : 0.1577, validation loss : 0.1339
[3/5] Train loss : 0.1673, validation loss : 0.1961
[4/5] Train loss : 0.1706, validation loss : 0.2200
[5/5] Train loss : 0.1708, validation loss : 0.2474
2022-12-15 04:09:43,949 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:09:43,949 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0454, validation loss : 0.0880
[2/5] Train loss : 0.0451, validation loss : 0.0880
[3/5] Train loss : 0.0452, validation loss : 0.0880
[4/5] Train loss : 0.0454, validation loss : 0.0880
[5/5] Train loss : 0.0450, validation loss : 0.0880
2022-12-15 04:10:04,662 [DEBUG] Training from 2014, 2015
2022-12-15 04:10:04,704 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:10:04,706 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0275, validation loss : -0.0488
[2/5] Train loss : 0.0275, validation loss : -0.0488
[3/5] Train loss : 0.0275, validation loss : -0.0488
[4/5] Train loss : 0.0275, validation loss : -0.0488
[5/5] Train loss : 0.0275, validation loss : -0.0488
2022-12-15 04:14:07,368 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:14:07,368 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0497, validation loss : -0.1156
[2/5] Train loss : -0.0497, validation loss : -0.1156
[3/5] Train loss : -0.0497, validation loss : -0.1156
[4/5] Train loss : -0.0497, validation loss : -0.1156
[5/5] Train loss : -0.0497, validation loss : -0.1156
2022-12-15 04:14:20,858 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:14:20,858 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1666, validation loss : 0.0583
[2/5] Train loss : 0.1590, validation loss : 0.0585
[3/5] Train loss : 0.1611, validation loss : 0.0586
[4/5] Train loss : 0.1620, validation loss : 0.0587
[5/5] Train loss : 0.1624, validation loss : 0.0587
2022-12-15 04:15:09,085 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:15:09,086 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1631, validation loss : 0.0578
[2/5] Train loss : 0.1531, validation loss : 0.0585
[3/5] Train loss : 0.1600, validation loss : 0.0587
[4/5] Train loss : 0.1615, validation loss : 0.0587
[5/5] Train loss : 0.1623, validation loss : 0.0588
2022-12-15 04:19:10,664 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:19:10,665 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0275, validation loss : -0.0488
[2/5] Train loss : 0.0275, validation loss : -0.0488
[3/5] Train loss : 0.0275, validation loss : -0.0488
[4/5] Train loss : 0.0275, validation loss : -0.0487
[5/5] Train loss : 0.0275, validation loss : -0.0488
2022-12-15 04:19:27,732 [DEBUG] Training from 2016, 2017
2022-12-15 04:19:27,762 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:19:27,763 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0295, validation loss : 0.1060
[2/5] Train loss : 0.0295, validation loss : 0.1060
[3/5] Train loss : 0.0295, validation loss : 0.1060
[4/5] Train loss : 0.0295, validation loss : 0.1060
[5/5] Train loss : 0.0295, validation loss : 0.1060
2022-12-15 04:23:24,932 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:23:24,932 [DEBUG] [+] Training model...
[1/5] Train loss : -0.0012, validation loss : 0.0919
[2/5] Train loss : -0.0012, validation loss : 0.0919
[3/5] Train loss : -0.0012, validation loss : 0.0919
[4/5] Train loss : -0.0012, validation loss : 0.0919
[5/5] Train loss : -0.0012, validation loss : 0.0919
2022-12-15 04:23:38,560 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:23:38,561 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1248, validation loss : 0.3562
[2/5] Train loss : 0.1261, validation loss : 0.3514
[3/5] Train loss : 0.1276, validation loss : 0.3511
[4/5] Train loss : 0.1280, validation loss : 0.3497
[5/5] Train loss : 0.1288, validation loss : 0.3502
2022-12-15 04:24:26,734 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:24:26,735 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1261, validation loss : 0.3528
[2/5] Train loss : 0.1295, validation loss : 0.3508
[3/5] Train loss : 0.1296, validation loss : 0.3498
[4/5] Train loss : 0.1325, validation loss : 0.3500
[5/5] Train loss : 0.1369, validation loss : 0.3502
2022-12-15 04:28:29,540 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:28:29,540 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0295, validation loss : 0.1060
[2/5] Train loss : 0.0295, validation loss : 0.1060
[3/5] Train loss : 0.0295, validation loss : 0.1060
[4/5] Train loss : 0.0295, validation loss : 0.1060
[5/5] Train loss : 0.0295, validation loss : 0.1060
2022-12-15 04:28:46,367 [DEBUG] Training from 2018, 2019
2022-12-15 04:28:46,396 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:28:46,397 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0341, validation loss : 0.0209
[2/5] Train loss : 0.0341, validation loss : 0.0209
[3/5] Train loss : 0.0341, validation loss : 0.0209
[4/5] Train loss : 0.0341, validation loss : 0.0209
[5/5] Train loss : 0.0341, validation loss : 0.0209
2022-12-15 04:32:40,473 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:32:40,474 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0092, validation loss : -0.0043
[2/5] Train loss : 0.0092, validation loss : -0.0043
[3/5] Train loss : 0.0092, validation loss : -0.0043
[4/5] Train loss : 0.0092, validation loss : -0.0043
[5/5] Train loss : 0.0092, validation loss : -0.0043
2022-12-15 04:32:53,648 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:32:53,648 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0208, validation loss : -0.0597
[2/5] Train loss : -0.0010, validation loss : -0.0586
[3/5] Train loss : -0.0003, validation loss : -0.0423
[4/5] Train loss : 0.0192, validation loss : 0.1999
[5/5] Train loss : 0.0347, validation loss : -0.0110
2022-12-15 04:33:39,157 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:33:39,157 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1116, validation loss : 0.1861
[2/5] Train loss : 0.1078, validation loss : 0.1832
[3/5] Train loss : 0.1158, validation loss : 0.1816
[4/5] Train loss : 0.1281, validation loss : 0.1803
[5/5] Train loss : 0.1413, validation loss : 0.1787
2022-12-15 04:37:32,601 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:37:32,602 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0341, validation loss : 0.0209
[2/5] Train loss : 0.0341, validation loss : 0.0209
[3/5] Train loss : 0.0341, validation loss : 0.0204
[4/5] Train loss : 0.0341, validation loss : 0.0209
[5/5] Train loss : 0.0341, validation loss : 0.0209
2022-12-15 04:37:49,781 [DEBUG] Training from 2020, 2021
2022-12-15 04:37:49,808 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:37:49,808 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1156, validation loss : 0.0871
[2/5] Train loss : 0.1156, validation loss : 0.0871
[3/5] Train loss : 0.1156, validation loss : 0.0871
[4/5] Train loss : 0.1156, validation loss : 0.0871
[5/5] Train loss : 0.1156, validation loss : 0.0871
2022-12-15 04:41:43,773 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:41:43,774 [DEBUG] [+] Training model...
[1/5] Train loss : 0.0668, validation loss : 0.0892
[2/5] Train loss : 0.0668, validation loss : 0.0892
[3/5] Train loss : 0.0668, validation loss : 0.0892
[4/5] Train loss : 0.0668, validation loss : 0.0892
[5/5] Train loss : 0.0668, validation loss : 0.0892
2022-12-15 04:41:56,564 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:41:56,564 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1023, validation loss : 0.1552
[2/5] Train loss : 0.2151, validation loss : 0.0965
[3/5] Train loss : 0.2027, validation loss : 0.1560
[4/5] Train loss : 0.1862, validation loss : 0.1721
[5/5] Train loss : 0.1861, validation loss : 0.1764
2022-12-15 04:42:42,696 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:42:42,697 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1948, validation loss : 0.1802
[2/5] Train loss : 0.2113, validation loss : 0.1639
[3/5] Train loss : 0.2114, validation loss : 0.1503
[4/5] Train loss : 0.2115, validation loss : 0.1436
[5/5] Train loss : 0.2115, validation loss : 0.1433
2022-12-15 04:46:47,969 [DEBUG] [+] Setting sgd optimizer
2022-12-15 04:46:47,970 [DEBUG] [+] Training model...
[1/5] Train loss : 0.1158, validation loss : 0.0871
[2/5] Train loss : 0.1156, validation loss : 0.0871
[3/5] Train loss : 0.1154, validation loss : 0.0871
[4/5] Train loss : 0.1156, validation loss : 0.0871
[5/5] Train loss : 0.1156, validation loss : 0.0871
2022-12-15 04:47:08,525 [DEBUG] Backtesting strategies
2022-12-15 04:47:08,544 [DEBUG] First year: 2008
2022-12-15 04:47:08,587 [DEBUG] First year: 2008
2022-12-15 04:47:08,592 [DEBUG] First year: 2008
2022-12-15 04:47:08,602 [DEBUG] First year: 2008
2022-12-15 04:47:08,649 [DEBUG] First year: 2008
2022-12-15 04:47:31,209 [DEBUG] Changing year: 2009
2022-12-15 04:47:31,252 [DEBUG] Changing year: 2009
2022-12-15 04:47:31,258 [DEBUG] Changing year: 2009
2022-12-15 04:47:31,264 [DEBUG] Changing year: 2009
2022-12-15 04:47:31,306 [DEBUG] Changing year: 2009
2022-12-15 04:47:59,991 [DEBUG] Changing year: 2010
2022-12-15 04:47:59,991 [DEBUG] Changing model: lstm - 0
2022-12-15 04:48:00,038 [DEBUG] Changing year: 2010
2022-12-15 04:48:00,040 [DEBUG] Changing model: tcn - 0
2022-12-15 04:48:00,043 [DEBUG] Changing year: 2010
2022-12-15 04:48:00,044 [DEBUG] Changing model: rnn - 0
2022-12-15 04:48:00,052 [DEBUG] Changing year: 2010
2022-12-15 04:48:00,052 [DEBUG] Changing model: gru - 0
2022-12-15 04:48:00,102 [DEBUG] Changing year: 2010
2022-12-15 04:48:00,103 [DEBUG] Changing model: transformer - 0
2022-12-15 04:48:28,749 [DEBUG] Changing year: 2011
2022-12-15 04:48:28,790 [DEBUG] Changing year: 2011
2022-12-15 04:48:28,795 [DEBUG] Changing year: 2011
2022-12-15 04:48:28,805 [DEBUG] Changing year: 2011
2022-12-15 04:48:28,849 [DEBUG] Changing year: 2011
2022-12-15 04:48:57,283 [DEBUG] Changing year: 2012
2022-12-15 04:48:57,283 [DEBUG] Changing model: lstm - 1
2022-12-15 04:48:57,325 [DEBUG] Changing year: 2012
2022-12-15 04:48:57,327 [DEBUG] Changing model: tcn - 1
2022-12-15 04:48:57,330 [DEBUG] Changing year: 2012
2022-12-15 04:48:57,331 [DEBUG] Changing model: rnn - 1
2022-12-15 04:48:57,337 [DEBUG] Changing year: 2012
2022-12-15 04:48:57,337 [DEBUG] Changing model: gru - 1
2022-12-15 04:48:57,378 [DEBUG] Changing year: 2012
2022-12-15 04:48:57,380 [DEBUG] Changing model: transformer - 1
2022-12-15 04:49:25,126 [DEBUG] Changing year: 2013
2022-12-15 04:49:25,169 [DEBUG] Changing year: 2013
2022-12-15 04:49:25,180 [DEBUG] Changing year: 2013
2022-12-15 04:49:25,190 [DEBUG] Changing year: 2013
2022-12-15 04:49:25,252 [DEBUG] Changing year: 2013
2022-12-15 04:49:54,083 [DEBUG] Changing year: 2014
2022-12-15 04:49:54,083 [DEBUG] Changing model: lstm - 2
2022-12-15 04:49:54,123 [DEBUG] Changing year: 2014
2022-12-15 04:49:54,125 [DEBUG] Changing model: tcn - 2
2022-12-15 04:49:54,128 [DEBUG] Changing year: 2014
2022-12-15 04:49:54,128 [DEBUG] Changing model: rnn - 2
2022-12-15 04:49:54,137 [DEBUG] Changing year: 2014
2022-12-15 04:49:54,137 [DEBUG] Changing model: gru - 2
2022-12-15 04:49:54,187 [DEBUG] Changing year: 2014
2022-12-15 04:49:54,190 [DEBUG] Changing model: transformer - 2
2022-12-15 04:50:22,525 [DEBUG] Changing year: 2015
2022-12-15 04:50:22,562 [DEBUG] Changing year: 2015
2022-12-15 04:50:22,569 [DEBUG] Changing year: 2015
2022-12-15 04:50:22,580 [DEBUG] Changing year: 2015
2022-12-15 04:50:22,623 [DEBUG] Changing year: 2015
2022-12-15 04:50:52,662 [DEBUG] Changing year: 2016
2022-12-15 04:50:52,662 [DEBUG] Changing model: lstm - 3
2022-12-15 04:50:52,701 [DEBUG] Changing year: 2016
2022-12-15 04:50:52,703 [DEBUG] Changing model: tcn - 3
2022-12-15 04:50:52,707 [DEBUG] Changing year: 2016
2022-12-15 04:50:52,707 [DEBUG] Changing model: rnn - 3
2022-12-15 04:50:52,714 [DEBUG] Changing year: 2016
2022-12-15 04:50:52,714 [DEBUG] Changing model: gru - 3
2022-12-15 04:50:52,759 [DEBUG] Changing year: 2016
2022-12-15 04:50:52,761 [DEBUG] Changing model: transformer - 3
2022-12-15 04:51:21,360 [DEBUG] Changing year: 2017
2022-12-15 04:51:21,407 [DEBUG] Changing year: 2017
2022-12-15 04:51:21,416 [DEBUG] Changing year: 2017
2022-12-15 04:51:21,423 [DEBUG] Changing year: 2017
2022-12-15 04:51:21,465 [DEBUG] Changing year: 2017
2022-12-15 04:51:51,164 [DEBUG] Changing year: 2018
2022-12-15 04:51:51,165 [DEBUG] Changing model: lstm - 4
2022-12-15 04:51:51,208 [DEBUG] Changing year: 2018
2022-12-15 04:51:51,210 [DEBUG] Changing model: tcn - 4
2022-12-15 04:51:51,214 [DEBUG] Changing year: 2018
2022-12-15 04:51:51,215 [DEBUG] Changing model: rnn - 4
2022-12-15 04:51:51,226 [DEBUG] Changing year: 2018
2022-12-15 04:51:51,227 [DEBUG] Changing model: gru - 4
2022-12-15 04:51:51,278 [DEBUG] Changing year: 2018
2022-12-15 04:51:51,281 [DEBUG] Changing model: transformer - 4
2022-12-15 04:52:19,821 [DEBUG] Changing year: 2019
2022-12-15 04:52:19,859 [DEBUG] Changing year: 2019
2022-12-15 04:52:19,865 [DEBUG] Changing year: 2019
2022-12-15 04:52:19,871 [DEBUG] Changing year: 2019
2022-12-15 04:52:19,912 [DEBUG] Changing year: 2019
2022-12-15 04:52:49,371 [DEBUG] Changing year: 2020
2022-12-15 04:52:49,372 [DEBUG] Changing model: lstm - 5
2022-12-15 04:52:49,419 [DEBUG] Changing year: 2020
2022-12-15 04:52:49,422 [DEBUG] Changing model: tcn - 5
2022-12-15 04:52:49,428 [DEBUG] Changing year: 2020
2022-12-15 04:52:49,428 [DEBUG] Changing model: rnn - 5
2022-12-15 04:52:49,437 [DEBUG] Changing year: 2020
2022-12-15 04:52:49,438 [DEBUG] Changing model: gru - 5
2022-12-15 04:52:49,499 [DEBUG] Changing year: 2020
2022-12-15 04:52:49,502 [DEBUG] Changing model: transformer - 5
2022-12-15 04:53:18,275 [DEBUG] Changing year: 2021
2022-12-15 04:53:18,320 [DEBUG] Changing year: 2021
2022-12-15 04:53:18,325 [DEBUG] Changing year: 2021
2022-12-15 04:53:18,335 [DEBUG] Changing year: 2021
2022-12-15 04:53:18,398 [DEBUG] Changing year: 2021
2022-12-15 04:53:48,018 [DEBUG] Changing year: 2022
2022-12-15 04:53:48,018 [DEBUG] Changing model: lstm - 6
2022-12-15 04:53:48,066 [DEBUG] Changing year: 2022
2022-12-15 04:53:48,068 [DEBUG] Changing model: tcn - 6
2022-12-15 04:53:48,071 [DEBUG] Changing year: 2022
2022-12-15 04:53:48,071 [DEBUG] Changing model: rnn - 6
2022-12-15 04:53:48,080 [DEBUG] Changing year: 2022
2022-12-15 04:53:48,081 [DEBUG] Changing model: gru - 6
2022-12-15 04:53:48,140 [DEBUG] Changing year: 2022
2022-12-15 04:53:48,143 [DEBUG] Changing model: transformer - 6
2022-12-15 04:54:10,057 [DEBUG] Backtesting results
2022-12-15 04:54:10,057 [DEBUG] ---------------------------------
2022-12-15 04:54:10,057 [DEBUG] Results of strategy: random
2022-12-15 04:54:10,058 [DEBUG] Expected returns: 14.093451276980545%
2022-12-15 04:54:10,058 [DEBUG] Volatilty: 38.0617532032242%
2022-12-15 04:54:10,059 [DEBUG] Sharpe Ratio: 0.3702785628851877
2022-12-15 04:54:10,059 [DEBUG] MDD: -1.3763308489161217
2022-12-15 04:54:10,059 [DEBUG] ---------------------------------
2022-12-15 04:54:10,060 [DEBUG] Results of strategy: equal strategy
2022-12-15 04:54:10,061 [DEBUG] Expected returns: 19.099810829319914%
2022-12-15 04:54:10,061 [DEBUG] Volatilty: 27.671778722561047%
2022-12-15 04:54:10,061 [DEBUG] Sharpe Ratio: 0.6902270728895237
2022-12-15 04:54:10,062 [DEBUG] MDD: -1.2121061373370512
2022-12-15 04:54:10,062 [DEBUG] ---------------------------------
2022-12-15 04:54:10,062 [DEBUG] Results of strategy: lstm
2022-12-15 04:54:10,063 [DEBUG] Expected returns: 16.75912185542266%
2022-12-15 04:54:10,064 [DEBUG] Volatilty: 12.313488150016244%
2022-12-15 04:54:10,064 [DEBUG] Sharpe Ratio: 1.3610377215005929
2022-12-15 04:54:10,064 [DEBUG] MDD: -1.3611000879991173
2022-12-15 04:54:10,064 [DEBUG] ---------------------------------
2022-12-15 04:54:10,064 [DEBUG] Results of strategy: tcn
2022-12-15 04:54:10,065 [DEBUG] Expected returns: 10.447495590431913%
2022-12-15 04:54:10,065 [DEBUG] Volatilty: 16.451444428516638%
2022-12-15 04:54:10,065 [DEBUG] Sharpe Ratio: 0.6350503529235653
2022-12-15 04:54:10,067 [DEBUG] MDD: -1.4165531246890066
2022-12-15 04:54:10,067 [DEBUG] ---------------------------------
2022-12-15 04:54:10,067 [DEBUG] Results of strategy: rnn
2022-12-15 04:54:10,070 [DEBUG] Expected returns: 10.106117641453176%
2022-12-15 04:54:10,070 [DEBUG] Volatilty: 10.476159898634291%
2022-12-15 04:54:10,071 [DEBUG] Sharpe Ratio: 0.9646776814441945
2022-12-15 04:54:10,071 [DEBUG] MDD: -1.706528377887026
2022-12-15 04:54:10,071 [DEBUG] ---------------------------------
2022-12-15 04:54:10,071 [DEBUG] Results of strategy: gru
2022-12-15 04:54:10,073 [DEBUG] Expected returns: 8.519065492194047%
2022-12-15 04:54:10,073 [DEBUG] Volatilty: 7.728635361690067%
2022-12-15 04:54:10,073 [DEBUG] Sharpe Ratio: 1.1022729231633892
2022-12-15 04:54:10,074 [DEBUG] MDD: -1.7538805901485321
2022-12-15 04:54:10,074 [DEBUG] ---------------------------------
2022-12-15 04:54:10,074 [DEBUG] Results of strategy: transformer
2022-12-15 04:54:10,076 [DEBUG] Expected returns: 16.759121638310006%
2022-12-15 04:54:10,076 [DEBUG] Volatilty: 12.31348812689839%
2022-12-15 04:54:10,076 [DEBUG] Sharpe Ratio: 1.3610377064237618
2022-12-15 04:54:10,077 [DEBUG] MDD: -1.3611000430982523
2022-12-15 04:54:10,246 [DEBUG] Saving results
2022-12-15 04:54:10,625 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,625 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,625 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,626 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,626 [DEBUG] STREAM b'IDAT' 78 1189
2022-12-15 04:54:10,630 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,630 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,630 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,630 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,630 [DEBUG] STREAM b'IDAT' 78 2994
2022-12-15 04:54:10,691 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,691 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,692 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,692 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,692 [DEBUG] STREAM b'IDAT' 78 374
2022-12-15 04:54:10,694 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,694 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,694 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,694 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,694 [DEBUG] STREAM b'IDAT' 78 286
2022-12-15 04:54:10,696 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,696 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,696 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,696 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,696 [DEBUG] STREAM b'IDAT' 78 263
2022-12-15 04:54:10,698 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,698 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,698 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,698 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,698 [DEBUG] STREAM b'IDAT' 78 387
2022-12-15 04:54:10,700 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,700 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,700 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,700 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,700 [DEBUG] STREAM b'IDAT' 78 436
2022-12-15 04:54:10,702 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,702 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,702 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,702 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,702 [DEBUG] STREAM b'IDAT' 78 351
2022-12-15 04:54:10,704 [DEBUG] STREAM b'IHDR' 16 13
2022-12-15 04:54:10,704 [DEBUG] STREAM b'sBIT' 41 4
2022-12-15 04:54:10,704 [DEBUG] b'sBIT' 41 4 (unknown)
2022-12-15 04:54:10,704 [DEBUG] STREAM b'pHYs' 57 9
2022-12-15 04:54:10,705 [DEBUG] STREAM b'IDAT' 78 364
2022-12-15 04:54:11,532 [DEBUG] Saving models
